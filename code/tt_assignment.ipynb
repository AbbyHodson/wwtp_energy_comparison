{"cells":[{"cell_type":"markdown","source":["Date: 1/05/2026\n","\n","Point of Contact: Abigayle Hodson, Abigayle_Hodson@lbl.gov\n","\n","Organization: Lawrence Berkeley National Laboratory\n","\n","Purpose: The purpose of this notebook is to use data from a variety of sources, primarily various releases of the Clean Watersheds Needs Survey (CWNS), to create a dataframe of active wastewater resource recovery facilities in the United States for a specified year and assign one or more treatment trains to each wastewater treatment plant based on (Tarallo et al., 2015) or (El Abbadi et al., 2025).\n","\n","Data Sources:\n","*   Clean Watersheds Needs Survey (CWNS) (U.S. EPA, [2004](https://www.epa.gov/cwns/clean-watersheds-needs-survey-cwns-2004-report-and-data), [2008](https://ordspub.epa.gov/ords/cwns2008/f?p=cwns2008:25:), [2012](https://ordspub.epa.gov/ords/cwns2012/f?p=cwns2012:25:), and [2022](https://sdwis.epa.gov/ords/sfdw_pub/r/sfdw/cwns_pub/data-download?session=9748529459785))\n","*   Combined Heat and Power and Microgrid Installation Databases\n","[(U.S. DOE, 2024)](https://doe.icfwebservices.com/downloads/chp)\n","*   Water Environment Federation Biogas Database ([WEF, 2024](https://app.powerbi.com/view?r=eyJrIjoiMGFjZDFjZmItMjQ5Yi00ZTlhLWJmNTQtODFiNjlkYjFlODJjIiwidCI6ImI3ZTk3ODAyLTJhNjktNDc3ZS1iN2QyLWY0ZDE2MWMyMTBjYiIsImMiOjF9))"],"metadata":{"id":"IiInbKv2DVeA"},"id":"IiInbKv2DVeA"},{"cell_type":"code","execution_count":null,"id":"1f9e955d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1672,"status":"ok","timestamp":1767636921233,"user":{"displayName":"Abigayle Hodson","userId":"02880304820331263887"},"user_tz":480},"id":"1f9e955d","outputId":"f6aec796-1242-4663-9bbb-84baff52eb51"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["#mount google drive - establishes a connection between Google Drive and Colab notebook\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)\n","\n","#import necessary libraries\n","import pandas as pd\n","import numpy as np\n","\n","#display all columns in dataframe\n","pd.set_option('display.max_columns', None)\n","\n","#establish file path for ease of uploads and exports\n","path = './'"]},{"cell_type":"code","source":["#specify year to perform treatment train assignments for (e.g. scenario = 2012 reflects treatment configurations in 2012)\n","scenario = 2042 #options = [2012, 2042]\n","\n","#specify method for treatment train assignment\n","method = 'Tarallo et al., 2015' #options = ['Tarallo et al., 2015', 'El Abbadi et al., 2025']\n","\n","#based on method specified above, determine whether or not facilities with insufficient unit process information are assigned a treatment train based on common configurations in the area\n","if method == 'El Abbadi et al., 2025':\n","  assign_missing_facilities = True\n","else:\n","  assign_missing_facilities = False"],"metadata":{"id":"NaZIOFMLiRTW"},"id":"NaZIOFMLiRTW","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Create dataframe of active wastewater treatment facilities for given scenario"],"metadata":{"id":"yXoIbjK5QQFk"},"id":"yXoIbjK5QQFk"},{"cell_type":"code","source":["def create_wwtp_inventory(scenario):\n","  '''\n","  Function that creates an inventory of active wwtps in the United States for a given scenario using CWNS data\n","    Parameters:\n","      scenario = year (2012, 2022, or 2042)\n","    Returns:\n","      wwtps_all = dataframe containing the active wwtps and relevant characteristics (ie. location, flow rate, and nutrient removal flags) for given scenario\n","  '''\n","  if scenario == 2012:\n","    #upload facility flow rates from 2012 CWNS\n","    flow = pd.read_excel(path + 'input_data/facility_information/cwns/2012/SUMMARY_FLOW.xlsx', sheet_name = 'SUMMARY_FLOW', dtype = {'CWNS_NUMBER':str})\n","\n","    #filter to facilities that reported non-zero, non-nan flow in 2012\n","    flow = flow.loc[(flow['EXIST_TOTAL'] != 0) & (~pd.isna(flow['EXIST_TOTAL']))]\n","    flow.reset_index(inplace = True, drop = True)\n","\n","    #create dataframe of active wwtps based on facilities that reported flow in 2012\n","    wwtps_all = flow[['CWNS_NUMBER', 'EXIST_TOTAL']].rename(columns = {'EXIST_TOTAL':'2012_FLOW_MGD'})\n","\n","    #upload columns indicating nutrient removal processes\n","    nutr_rem = pd.read_excel(path + 'input_data/facility_information/cwns/2012/SUMMARY_EFFLUENT.xlsx', sheet_name = 'SUMMARY_EFFLUENT', dtype = {'CWNS_NUMBER':str})\n","    nutr_rem = nutr_rem[['CWNS_NUMBER','PRES_NITROGEN_REMOVAL','PRES_PHOSPHOROUS_REMOVAL','PRES_AMMONIA_REMOVAL']]\n","\n","    #merge nutrient removal information with main dataframe and rename columns\n","    wwtps_all = wwtps_all.merge(nutr_rem, on = 'CWNS_NUMBER', how = 'left')\n","\n","    #upload facility locations\n","    locations = pd.read_excel(path + 'input_data/facility_information/cwns/2012/SUMMARY_FACILITY.xlsx', sheet_name = 'SUMMARY_FACILITY', dtype = {'CWNS_NUMBER':str})\n","\n","    #add state column to main dataframe\n","    wwtps_all = wwtps_all.merge(locations[['CWNS_NUMBER','STATE']], on = 'CWNS_NUMBER', how = 'left')\n","    wwtps_all.rename(columns = {'CWNS_NUMBER':'CWNS_NUM'}, inplace = True)\n","\n","    #upload facility types\n","    types = pd.read_excel(path + 'input_data/facility_information/cwns/2012/SUMMARY_FACILITY_TYPE.xlsx', sheet_name = 'SUMMARY_FACILITY_TYPE', dtype = {'CWNS_NUMBER':str}).rename(columns= {'CWNS_NUMBER':'CWNS_NUM'})\n","\n","    #filter to treatment plants and lagoons\n","    types = types.loc[(types['FACILITY_TYPE'] == 'Treatment Plant') | (types['FACILITY_TYPE'] == 'Treatment Lagoon or Pond')].drop_duplicates(subset = 'CWNS_NUM')\n","\n","    #merge facility types with main dataframe to screen out non-treatment plants and honey bucket lagoons from inventory\n","    wwtps_all = wwtps_all.merge(types[['CWNS_NUM','FACILITY_TYPE']], on = 'CWNS_NUM', how = 'inner')\n","\n","    #check for facilities with duplicate entries\n","    assert wwtps_all['CWNS_NUM'].value_counts().max() == 1\n","\n","  elif scenario == 2022:\n","    #upload facility flow rates from 2022 CWNS\n","    flow = pd.read_csv(path + 'input_data/facility_information/cwns/2022/FLOW.csv', dtype = {'CWNS_ID':str})\n","\n","    #filter to total flow\n","    flow = flow.loc[flow['FLOW_TYPE'] == 'Total Flow']\n","\n","    #filter to facilities that report non-zero, non-nan flow in 2022\n","    flow = flow.loc[(flow['CURRENT_DESIGN_FLOW'] != 0) & (~pd.isna(flow['CURRENT_DESIGN_FLOW']))]\n","    flow.reset_index(inplace = True, drop = True)\n","\n","    #create dataframe of active wwtps based on facilities that report flow in 2022\n","    wwtps_all = flow[['CWNS_ID', 'CURRENT_DESIGN_FLOW']].rename(columns = {'CURRENT_DESIGN_FLOW':'2022_FLOW_MGD'})\n","\n","    #upload columns indicating nutrient removal in 2012 (note, 2022 CWNS does not include these columns, so we have to rely on outdated information)\n","    nutr_rem = pd.read_excel(path + 'input_data/facility_information/cwns/2012/SUMMARY_EFFLUENT.xlsx', sheet_name = 'SUMMARY_EFFLUENT', dtype = {'CWNS_NUMBER':str})\n","    nutr_rem = nutr_rem[['CWNS_NUMBER','PRES_NITROGEN_REMOVAL','PRES_PHOSPHOROUS_REMOVAL','PRES_AMMONIA_REMOVAL']].rename(columns = {'CWNS_NUMBER':'CWNS_ID'})\n","\n","    #merge nutrient removal information with main dataframe and rename columns\n","    wwtps_all = wwtps_all.merge(nutr_rem, on = 'CWNS_ID', how = 'left')\n","\n","    #upload facility locations\n","    locations = pd.read_csv(path + 'input_data/facility_information/cwns/2022/PHYSICAL_LOCATION.csv', dtype = {'CWNS_ID':str})\n","\n","    #add state column to main dataframe\n","    wwtps_all = wwtps_all.merge(locations[['CWNS_ID','STATE_CODE']], on = 'CWNS_ID', how = 'left')\n","    wwtps_all.rename(columns = {'CWNS_ID':'CWNS_NUM','STATE_CODE':'STATE'}, inplace = True)\n","\n","    #upload facility types\n","    types = pd.read_csv(path + 'input_data/facility_information/cwns/2022/FACILITY_TYPES.csv', dtype = {'CWNS_ID':str}).rename(columns= {'CWNS_ID':'CWNS_NUM'})\n","\n","    #filter to just treatment plants and honey bucket lagoons\n","    types = types.loc[(types['FACILITY_TYPE'] == 'Treatment Plant') | (types['FACILITY_TYPE'] == 'Honey Bucket Lagoon')].drop_duplicates(subset = 'CWNS_NUM')\n","\n","    #merge facility types with main dataframe to screen out non-treatment plants and honey bucket lagoons from inventory\n","    wwtps_all = wwtps_all.merge(types[['CWNS_NUM','FACILITY_TYPE']], on = 'CWNS_NUM', how = 'inner')\n","\n","    #check for facilities with duplicate entries\n","    assert wwtps_all['CWNS_NUM'].value_counts().max() == 1\n","\n","  else:\n","    #upload projected facility flow rates from the 2022 CWNS\n","    flow = pd.read_csv(path + 'input_data/facility_information/cwns/2022/FLOW.csv', dtype = {'CWNS_ID':str})\n","\n","    #filter to total flow\n","    flow = flow.loc[flow['FLOW_TYPE'] == 'Total Flow']\n","\n","    #filter to facilities that project non-zero, non-nan flow in 2042\n","    flow = flow.loc[(flow['FUTURE_DESIGN_FLOW'] != 0) & (~pd.isna(flow['FUTURE_DESIGN_FLOW']))]\n","    flow.reset_index(inplace = True, drop = True)\n","\n","    #create dataframe of active wwtps based on facilities that project flow in 2042\n","    wwtps_all = flow[['CWNS_ID', 'FUTURE_DESIGN_FLOW']].rename(columns = {'FUTURE_DESIGN_FLOW':'2042_FLOW_MGD'})\n","\n","    #upload columns indicating projected nutrient removal in 2012 (note, 2022 CWNS does not include these columns, so we have to rely on outdated information)\n","    nutr_rem = pd.read_excel(path + 'input_data/facility_information/cwns/2012/SUMMARY_EFFLUENT.xlsx', sheet_name = 'SUMMARY_EFFLUENT', dtype = {'CWNS_NUMBER':str})\n","    nutr_rem = nutr_rem[['CWNS_NUMBER','PROJ_NITROGEN_REMOVAL','PROJ_PHOSPHOROUS_REMOVAL','PROJ_AMMONIA_REMOVAL']].rename(columns = {'CWNS_NUMBER':'CWNS_ID'})\n","\n","    #merge nutrient removal information with main dataframe and rename columns\n","    wwtps_all = wwtps_all.merge(nutr_rem, on = 'CWNS_ID', how = 'left')\n","\n","    #upload facility locations\n","    locations = pd.read_csv(path + 'input_data/facility_information/cwns/2022/PHYSICAL_LOCATION.csv', dtype = {'CWNS_ID':str})\n","\n","    #add state column to main dataframe\n","    wwtps_all = wwtps_all.merge(locations[['CWNS_ID','STATE_CODE']], on = 'CWNS_ID', how = 'left')\n","    wwtps_all.rename(columns = {'CWNS_ID':'CWNS_NUM','STATE_CODE':'STATE'}, inplace = True)\n","\n","    #upload facility types\n","    types = pd.read_csv(path + 'input_data/facility_information/cwns/2022/FACILITY_TYPES.csv', dtype = {'CWNS_ID':str}).rename(columns= {'CWNS_ID':'CWNS_NUM'})\n","\n","    #filter to just treatment plants and honey bucket lagoons\n","    types = types.loc[(types['FACILITY_TYPE'] == 'Treatment Plant') | (types['FACILITY_TYPE'] == 'Honey Bucket Lagoon')].drop_duplicates(subset = 'CWNS_NUM')\n","    types.reset_index(inplace = True, drop = True)\n","\n","    #merge facility types with main dataframe to screen out non-treatment plants and honey bucket lagoons from inventory\n","    wwtps_all = wwtps_all.merge(types[['CWNS_NUM','FACILITY_TYPE']], on = 'CWNS_NUM', how = 'inner')\n","\n","    #check for facilities with duplicate entries\n","    assert wwtps_all['CWNS_NUM'].value_counts().max() == 1\n","\n","  #categorize average daily flow rate\n","  wwtps_all.loc[wwtps_all[f'{str(scenario)}_FLOW_MGD'] < 2, f'{str(scenario)}_FLOW_CAT_MGD'] = 'LESS THAN 2'\n","  wwtps_all.loc[(wwtps_all[f'{str(scenario)}_FLOW_MGD'] >= 2) & (wwtps_all[f'{str(scenario)}_FLOW_MGD'] < 4), f'{str(scenario)}_FLOW_CAT_MGD'] = '2 TO 4'\n","  wwtps_all.loc[(wwtps_all[f'{str(scenario)}_FLOW_MGD'] >= 4) & (wwtps_all[f'{str(scenario)}_FLOW_MGD'] < 7), f'{str(scenario)}_FLOW_CAT_MGD'] = '4 TO 7'\n","  wwtps_all.loc[(wwtps_all[f'{str(scenario)}_FLOW_MGD'] >= 7) & (wwtps_all[f'{str(scenario)}_FLOW_MGD'] < 16), f'{str(scenario)}_FLOW_CAT_MGD'] = '7 TO 16'\n","  wwtps_all.loc[(wwtps_all[f'{str(scenario)}_FLOW_MGD'] >= 16) & (wwtps_all[f'{str(scenario)}_FLOW_MGD'] < 46), f'{str(scenario)}_FLOW_CAT_MGD'] = '16 TO 46'\n","  wwtps_all.loc[(wwtps_all[f'{str(scenario)}_FLOW_MGD'] >= 46) & (wwtps_all[f'{str(scenario)}_FLOW_MGD'] < 100), f'{str(scenario)}_FLOW_CAT_MGD'] = '46 TO 100'\n","  wwtps_all.loc[(wwtps_all[f'{str(scenario)}_FLOW_MGD'] >= 100), f'{str(scenario)}_FLOW_CAT_MGD'] = '100 AND ABOVE'\n","\n","  #upload EPA regions by state\n","  epa_regions = pd.read_csv(path + 'input_data/state_EPA_regions.csv', dtype = {'STATE':str})\n","\n","  #add column for EPA region\n","  wwtps_all = wwtps_all.merge(epa_regions, on = 'STATE', how = 'left')\n","\n","  return wwtps_all"],"metadata":{"id":"0jL20DCz6l_X"},"id":"0jL20DCz6l_X","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create dataframe of active wwtps for specified scenario\n","wwtps = create_wwtp_inventory(scenario)"],"metadata":{"id":"x8dTnDXkzM0N"},"id":"x8dTnDXkzM0N","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Compile unit process data"],"metadata":{"id":"l-UOeYq2QWqO"},"id":"l-UOeYq2QWqO"},{"cell_type":"code","execution_count":null,"id":"2f12d70d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":1539,"status":"ok","timestamp":1767636925635,"user":{"displayName":"Abigayle Hodson","userId":"02880304820331263887"},"user_tz":480},"id":"2f12d70d","outputId":"96f7e039-0f18-4308-adc1-7682b554d486"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-721677188.py:4: DtypeWarning: Columns (14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n","  up2004 = pd.read_csv(path + 'input_data/facility_information/cwns/2004/2004_Unit_Processes.csv', dtype = {'CWNS_NUMBER':str}, encoding = 'latin1')\n"]}],"source":["#read in unit processes reported in the 2004, 2008, and 2012 releases of CWNS\n","up2012 = pd.read_csv(path + 'input_data/facility_information/cwns/2012/2012_SUMMARY_UNIT_PROCESS.csv', dtype = {'CWNS_NUMBER':str}, encoding = 'latin1')\n","up2008 = pd.read_csv(path + 'input_data/facility_information/cwns/2008/2008_SUMMARY_UNIT_PROCESS.csv',dtype = {'CWNS_NUMBER':str}, encoding = 'latin1')\n","up2004 = pd.read_csv(path + 'input_data/facility_information/cwns/2004/2004_Unit_Processes.csv', dtype = {'CWNS_NUMBER':str}, encoding = 'latin1')\n","\n","#aggregate 2004, 2008, and 2012 unit process lists and drop/rename columns\n","up_old = pd.concat([up2012, up2008, up2004], axis = 0)\n","up_old.drop(['BACKUP_IND','PLANNED_YEAR','ADDITIONAL_NOTES','LAST_UPDATED_TS','BLANK','CHANGE_TYPE_CAT','SORT_SEQUENCE','KEEP_UP_CODE', 'CHGTP_NAME_CAT','TREATMENT_TYPE','Notes'], inplace = True, axis = 1)\n","up_old.rename(columns = {'CWNS_NUMBER':'CWNS_NUM'}, inplace = True)\n","\n","#add a leading zero to CWNS ids with a length less than 11 to ensure proper merge\n","up_old['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in up_old['CWNS_NUM']]\n","\n","#reconcile unit process naming conventions between different CWNS releases\n","upnames = pd.read_csv(path + 'input_data/facility_information/cwns/UNIT_PROCESS_NAMES.csv')\n","up_old = pd.merge(left = up_old, right = upnames, how = 'left', left_on = 'UNIT_PROCESS', right_on = 'ORIGINAL_UP_NAME')\n","up_old.drop(['ORIGINAL_UP_NAME'], inplace = True, axis = 1)\n","\n","#remove processes listed for abandoment in 2004, 2008, or 2012 and processes listed as both PRES_IND = N and PROJ_IND = N\n","up_old = up_old.loc[up_old['CHANGE_TYPE'] != 'Abandonment']\n","up_old = up_old.loc[~((up_old['PRES_IND'] == 'N') & (up_old['PROJ_IND'] == 'N'))]\n","up_old = up_old[['CWNS_NUM','REPORT_YEAR','PRES_IND','PROJ_IND','FINAL_UNIT_PROCESS_NAME']]\n","\n","#change formatting of present and projected indices to binary\n","up_old.loc[up_old['PRES_IND'] == 'Y', 'PRES_IND'] = 1\n","up_old.loc[up_old['PRES_IND'] == 'N', 'PRES_IND'] = 0\n","up_old.loc[up_old['PROJ_IND'] == 'Y', 'PROJ_IND'] = 1\n","up_old.loc[up_old['PROJ_IND'] == 'N', 'PROJ_IND'] = 0\n","\n","#read in unit processes from the 2022 CWNS\n","up2022 = pd.read_csv(path + 'input_data/facility_information/cwns/2022/UNIT_PROCESSES.csv', dtype = {'CWNS_ID' : str})\n","up2022.rename(columns = {'CWNS_ID':'CWNS_NUM'}, inplace = True)\n","\n","#add a leading zero to CWNS ids with a length less than 11 to ensure proper merge\n","up2022['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in up2022['CWNS_NUM']]\n","\n","#change formatting of 2022 unit process names to match that of prior years\n","#note: 'Biological Treatment, Other' was manually corrected to be more specific. 'Chemical N Removal' was assumed to be roughly the same energy intensity as 'Chemical P removal'\n","upnames_2022 = pd.read_csv(path + 'input_data/facility_information/cwns/UNIT_PROCESS_NAMES_2022.csv')\n","up2022 = pd.merge(left = up2022, right = upnames_2022, how = 'left', left_on = 'UNIT_PROCESS', right_on = '2022_UNIT_PROCESS_NAME')\n","\n","#filter to relevant columns and rename to match the formatting of old unit process dataframes\n","up2022 = up2022[['CWNS_NUM','FINAL_UNIT_PROCESS_NAME','EXISTING_FLAG','PLANNED_FLAG']]\n","up2022.rename(columns = {'EXISTING_FLAG':'PRES_IND','PLANNED_FLAG':'PROJ_IND'}, inplace = True)\n","up2022.loc[up2022['PRES_IND'] == 'Y', 'PRES_IND'] = 1\n","up2022.loc[up2022['PRES_IND'] == 'N', 'PRES_IND'] = 0\n","up2022.loc[pd.isna(up2022['PRES_IND']), 'PRES_IND'] = 0\n","up2022.loc[up2022['PROJ_IND'] == 'Y', 'PROJ_IND'] = 1\n","up2022.loc[up2022['PROJ_IND'] == 'N', 'PROJ_IND'] = 0\n","up2022.loc[pd.isna(up2022['PROJ_IND']), 'PROJ_IND'] = 0\n","up2022['REPORT_YEAR'] = 2022\n","\n","#create unit process list which contains information from 2004, 2008, 2012, and 2022 CWNS\n","uplist_all = pd.concat([up2022, up_old], axis = 0)\n","\n","#sort unit processes by reporting year\n","uplist_all.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = True, inplace = True)"]},{"cell_type":"code","execution_count":null,"id":"4d057429","metadata":{"id":"4d057429","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767636925863,"user_tz":480,"elapsed":224,"user":{"displayName":"Abigayle Hodson","userId":"02880304820331263887"}},"outputId":"587e84fb-df23-4106-f44f-e3a4016a4403"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1350442500.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  wef_biogas.replace('yes', 1, inplace = True)\n","/tmp/ipython-input-1350442500.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  wef_biogas.replace('no', 0, inplace = True)\n","/tmp/ipython-input-1350442500.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  wef_biogas.replace('unknown', 0, inplace = True)\n","/tmp/ipython-input-1350442500.py:50: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  biogas_all.fillna(0, inplace = True)\n"]}],"source":["#upload facilities identified as producing electricity in DOE's Combined Heat and Power Installation database, pre-filtered to wastewater treatment plants and manually assigned a CWNS number based on facility name and location\n","doe_biogas = pd.read_csv(path + 'input_data/facility_information/biogas/biogas_wwtps_doe.csv', dtype = {'CWNS_NUM':str})\n","\n","#drop facilities without an identified CWNS number\n","doe_biogas = doe_biogas.dropna(subset = ['CWNS_NUM'])\n","doe_biogas.reset_index(inplace = True, drop = True)\n","\n","#add a leading zero to facilities with improperly recorded CWNS number\n","doe_biogas['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in doe_biogas['CWNS_NUM']]\n","\n","#upload facilities identified as producing electricity in WEF's Biogas Database, downloaded prior to website update which removed option to download data\n","wef_biogas = pd.read_csv(path + 'input_data/facility_information/biogas/biogas_wwtps_wef.csv', dtype = {'CWNS_NUM':str})\n","\n","#drop facilities without an identified CWNS number\n","wef_biogas = wef_biogas.dropna(subset = 'CWNS_NUM')\n","\n","#add a leading zero to facilities with improperly recorded CWNS number\n","wef_biogas['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in wef_biogas['CWNS_NUM']]\n","\n","#add a column to indicate if electricity is produced from biogas\n","wef_biogas.replace('yes', 1, inplace = True)\n","wef_biogas.replace('no', 0, inplace = True)\n","wef_biogas.replace('unknown', 0, inplace = True)\n","wef_biogas['Electricity Produced?'] = wef_biogas['Electricity_from_combustion-engine'] + wef_biogas['Electricity_from_microturbine'] + wef_biogas['Electricity_from_turbine'] + wef_biogas['Electricity_from_fuelcell'] + wef_biogas['Electricity_supplied_to_grid']\n","wef_biogas.loc[wef_biogas['Electricity Produced?'] > 0, 'BIOGAS_WEF_2012'] = 1\n","wef_biogas.loc[wef_biogas['Electricity Produced?'] > 0, 'BIOGAS_WEF_2022'] = 1\n","wef_biogas.loc[wef_biogas['Electricity Produced?'] > 0, 'BIOGAS_WEF_PROJ'] = 1\n","\n","#upload facilities that project using energy recovery from the 2022 CWNS\n","cwns_biogas = pd.read_csv(path + 'input_data/facility_information/cwns/2022/UNIT_PROCESSES.csv', dtype = {'CWNS_NUM':str})\n","\n","#rename columns,\n","cwns_biogas.rename(columns = {'CWNS_ID':'CWNS_NUM'}, inplace = True)\n","\n","#add a leading zero to facilities with improperly recorded CWNS number\n","cwns_biogas['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in cwns_biogas['CWNS_NUM']]\n","\n","#filter to facilities that project using biogas for energy recovery\n","cwns_biogas = cwns_biogas.loc[(cwns_biogas['UNIT_PROCESS'] == 'Biosolids Anaerobic Digestion with Energy Recovery') & ((cwns_biogas['EXISTING_FLAG'] == 'Y') | (cwns_biogas['PLANNED_FLAG'] == 'Y'))]\n","cwns_biogas['BIOGAS_CWNS_PROJ'] = 1\n","cwns_biogas.rename(columns = {'EXISTING_FLAG':'BIOGAS_CWNS_2022'}, inplace = True)\n","cwns_biogas.loc[cwns_biogas['BIOGAS_CWNS_2022'] == 'Y', 'BIOGAS_CWNS_2022'] = 1\n","cwns_biogas['Prime Mover'] = 'Unknown'\n","cwns_biogas = cwns_biogas[['CWNS_NUM','Prime Mover','BIOGAS_CWNS_2022','BIOGAS_CWNS_PROJ']]\n","\n","#combine DOE, WEF, and CWNS biogas dataframes\n","biogas_all = pd.concat([cwns_biogas, doe_biogas, wef_biogas])\n","\n","#create columns that indicate if facility was flagged as producing electricity in either external database\n","biogas_all.fillna(0, inplace = True)\n","biogas_all.loc[biogas_all['BIOGAS_DOE_2012'] + biogas_all['BIOGAS_WEF_2012'] > 0, 'BIOGAS_2012'] = 1\n","biogas_all.loc[biogas_all['BIOGAS_CWNS_2022'] + biogas_all['BIOGAS_DOE_2022'] + biogas_all['BIOGAS_WEF_2022'] > 0, 'BIOGAS_2022'] = 1\n","biogas_all.loc[biogas_all['BIOGAS_CWNS_PROJ'] + biogas_all['BIOGAS_DOE_PROJ'] + biogas_all['BIOGAS_WEF_PROJ'] > 0, 'BIOGAS_2042'] = 1\n","\n","#filter to relevant columns and drop duplicates\n","biogas_all = biogas_all[['CWNS_NUM','BIOGAS_2012','BIOGAS_2022','BIOGAS_2042']]\n","biogas_all.drop_duplicates(subset = 'CWNS_NUM', inplace = True)\n","biogas_all.reset_index(inplace = True, drop = True)\n","\n","#add columns indicating biogas utilization for electricity production to main dataframe\n","wwtps = wwtps.merge(biogas_all, on = 'CWNS_NUM', how = 'left')\n","\n","#use supplementary biogas databases to add anaerobic digestion to unit process list for facilities flagged as using biogas for electricity production\n","doe_biogas_ad = doe_biogas[['CWNS_NUM','Latest Install Year']].rename(columns = {'Latest Install Year':'REPORT_YEAR'})\n","doe_biogas_ad['FINAL_UNIT_PROCESS_NAME'] = 'Biosolids Anaerobic Digestion, Other'\n","doe_biogas_ad['PRES_IND'] = 1\n","doe_biogas_ad['PROJ_IND'] = 1\n","\n","wef_biogas_ad = wef_biogas.loc[wef_biogas['AD'] == 1][['CWNS_NUM', 'AD']]\n","wef_biogas_ad['FINAL_UNIT_PROCESS_NAME'] = 'Biosolids Anaerobic Digestion, Other'\n","wef_biogas_ad['REPORT_YEAR'] = 2013\n","wef_biogas_ad['PRES_IND'] = 1\n","wef_biogas_ad['PROJ_IND'] = 1\n","wef_biogas_ad = wef_biogas_ad[['CWNS_NUM','FINAL_UNIT_PROCESS_NAME','REPORT_YEAR','PRES_IND','PROJ_IND']]\n","\n","cwns_biogas_ad = cwns_biogas[['CWNS_NUM','BIOGAS_CWNS_2022','BIOGAS_CWNS_PROJ']].rename(columns = {'BIOGAS_CWNS_2022':'PRES_IND','BIOGAS_CWNS_PROJ':'PROJ_IND'})\n","cwns_biogas_ad['FINAL_UNIT_PROCESS_NAME'] = 'Biosolids Anaerobic Digestion, Other'\n","cwns_biogas_ad['REPORT_YEAR'] = 2022\n","\n","#merge additional anaerobic digestion processes with cumulative unit process list\n","uplist_all = pd.concat([uplist_all, wef_biogas_ad, doe_biogas_ad, cwns_biogas_ad], axis = 0, ignore_index = False)"]},{"cell_type":"code","execution_count":null,"id":"558ee22c","metadata":{"id":"558ee22c","scrolled":true},"outputs":[],"source":["#assign key unit processes a code (ie. 'Activated Sludge' is assigned the code 'AS'); note, not all unit processes receive a code because not all processes are considered when forming treatment trains\n","up_eicodes = pd.read_csv(path + 'input_data/facility_information/cwns/UNIT_PROCESS_EI_CODES_WERF.csv')\n","uplist_eicodes = uplist_all.merge(up_eicodes[['FINAL_UNIT_PROCESS_NAME','WERF_CODE','DISPOSAL_CODE']].drop_duplicates(subset = ['FINAL_UNIT_PROCESS_NAME']), how = 'left', on = 'FINAL_UNIT_PROCESS_NAME')\n","\n","#drop unit processes that do not have an associated WERF code, as these are not necessary to form treatment train assignments\n","uplist_eicodes.dropna(subset = 'WERF_CODE', inplace = True)"]},{"cell_type":"code","execution_count":null,"id":"4f32bfaa","metadata":{"collapsed":true,"id":"4f32bfaa"},"outputs":[],"source":["#if using El Abbadi et al., 2025 method for 2022 or 2042, perform manual corrections to cumulative unit process list for large facilities that were initially assigned multiple treatment trains\n","if (method == 'El Abbadi et al., 2025') & (scenario != 2012):\n","  #fix Lewiston, ME; no nutrient removal\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '23000011001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '23000011001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","\n","  #fix Brockton, MA; no TF, no incineration\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'PROJ_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'MHI')), 'PROJ_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '25000024001') & ((uplist_eicodes['WERF_CODE'] == 'MHI')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","\n","  #fix GLWA plants; no phosphorus or nutrient removal\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000569001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000569001') & ((uplist_eicodes['WERF_CODE'] == 'AS-A2O')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","\n","  #fix WY WWTP; no trickling filter\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000334001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '26000334001') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","\n","  #fix Mcalpine Creek WWTP; no BNIT, LAGOON_AER, NIT, or TF; add biogas utilization\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'BNIT')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'BNIT')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'LAGOON_AER')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'LAGOON_AER')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'NIT')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'NIT')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '37006001002') & ((uplist_eicodes['WERF_CODE'] == 'TF')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  biogas_all[len(biogas_all)] = {'CWNS_NUM':'37006001002', 'BIOGAS_2012':np.nan, 'BIOGAS_2022':1, }\n","\n","  #fix NEORSD Westerly WWTP; no AND, AS, or CHEM-P\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AND')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AND')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AS')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'AS')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'CHEM-P')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '39001666003') & ((uplist_eicodes['WERF_CODE'] == 'CHEM-P')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","\n","  #fix Hopewell Regional WWTP; no FBI, add MHI\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '51000238001') & ((uplist_eicodes['WERF_CODE'] == 'FBI')), 'PRES_IND'] = 0\n","  uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == '51000238001') & ((uplist_eicodes['WERF_CODE'] == 'FBI')), 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","  hopewell_idx = uplist_eicodes[uplist_eicodes['CWNS_NUM'] == '51000238001'].index.max()\n","  hopewell_add = pd.Series({'CWNS_NUM': '51000238001', 'WERF_CODE': 'MHI', 'PRES_IND': 1, 'FINAL_UNIT_PROCESS_NAME': 'Biosolids Incineration, Multiple Hearth', 'UP_ID_NOTE': 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'}).to_frame().T\n","  uplist_eicodes = pd.concat([uplist_eicodes.iloc[:hopewell_idx], hopewell_add, uplist_eicodes.iloc[hopewell_idx:]], ignore_index=True)\n","\n","  #fix Arlington, CO WPCP; add LIME\n","  arlington_idx = uplist_eicodes[uplist_eicodes['CWNS_NUM'] == '51000319001'].index.max()\n","  arlington_add = pd.Series({'CWNS_NUM': '51000319001', 'WERF_CODE': 'LIME', 'PRES_IND': 1, 'FINAL_UNIT_PROCESS_NAME': 'Biosolids Lime Stabilization', 'UP_ID_NOTE': 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'}).to_frame().T\n","  uplist_eicodes = pd.concat([uplist_eicodes.iloc[:arlington_idx], arlington_add, uplist_eicodes.iloc[arlington_idx:]], ignore_index=True)\n","\n","  #fix Lewiston, ME; remove nutrient removal\n","  wwtps.loc[wwtps['CWNS_NUM'] == '23000011001', 'PRES_NITROGEN_REMOVAL'] = 0\n","  wwtps.loc[wwtps['CWNS_NUM'] == '23000011001', 'PRES_PHOSPHOROUS_REMOVAL'] = 0\n","  wwtps.loc[wwtps['CWNS_NUM'] == '23000011001', 'PRES_AMMONIA_REMOVAL'] = 0\n","  uplist_eicodes.loc[uplist_eicodes['CWNS_NUM'] == '23000011001', 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'\n","\n","  #fix GLWA plants; no phosphorus or nutrient removal yet\n","  wwtps.loc[wwtps['CWNS_NUM'] == '26000569001', 'PRES_NITROGEN_REMOVAL'] = 0\n","  wwtps.loc[wwtps['CWNS_NUM'] == '26000569001', 'PRES_PHOSPHOROUS_REMOVAL'] = 0\n","  wwtps.loc[wwtps['CWNS_NUM'] == '26000569001', 'PRES_AMMONIA_REMOVAL'] = 0\n","  uplist_eicodes.loc[uplist_eicodes['CWNS_NUM'] == '26000569001', 'UP_ID_NOTE'] = 'Corrected based on manual check of large facilities with multiple treatment train assignments (2023)'"]},{"cell_type":"code","execution_count":null,"id":"250f9e05","metadata":{"id":"250f9e05"},"outputs":[],"source":["#if using El Abbadi et al., 2025 method for 2022 or 2042, perform manual corrections to cumulative unit process list to add and remove lagoons\n","if (method == 'El Abbadi et al., 2025') & (scenario != 2012):\n","  #import list of lagoons to add from EPA lagoon inventory and manual checks\n","  lagoon_add = pd.read_csv(path + 'input_data/facility_information/manual_corrections/cwns_lagoon_add_ttrains_info.csv', dtype = {'CWNS_NUM':str})\n","\n","  #add leading zeros to CWNS ids to ensure proper merge with other datasets\n","  lagoon_add['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in lagoon_add['CWNS_NUM']]\n","\n","  #add in columns for concatenation with main uplist_eicodes dataframe\n","  lagoon_add['REPORT_YEAR'] = 2022\n","  lagoon_add['UP_ID_NOTE'] = 'Assigned using updated data on the presence of lagoons from EPA (2022)'\n","  lagoon_add['PRES_IND'] = 1\n","  lagoon_add['PROJ_IND'] = 1\n","  lagoon_add.rename(columns = {'LAGOON_CODE':'WERF_CODE','LAGOON_NAME':'FINAL_UNIT_PROCESS_NAME'}, inplace = True)\n","\n","  #concatenate dataframe which contains additional lagoons found in EPA survey/manual checks and main unit process list dataframe\n","  uplist_eicodes = pd.concat([uplist_eicodes, lagoon_add], axis = 0)\n","\n","  #import list of lagoons to remove based on manual checks\n","  lagoon_removed = pd.read_csv(path + 'input_data/facility_information/manual_corrections/cwns_lagoon_remove.csv', dtype = {'CWNS_NUM': str})\n","\n","  #add leading zeros to CWNS ids to ensure proper match with uplist_eicodes\n","  lagoon_removed['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in lagoon_removed['CWNS_NUM']]\n","\n","  #loop through lagoons that need to be removed\n","  for index, row in lagoon_removed.iterrows():\n","      #retrieve CWNS number and lagoon code to remove\n","      lagoon_removed_CWNS = row['CWNS_NUM']\n","      lagoon_removed_code = row['REMOVE']\n","\n","      #search for the row in uplist_eicodes where the CWNS number matches the CWNS number in lagoon_removed\n","      CWNS_match_row = uplist_eicodes.loc[(uplist_eicodes['CWNS_NUM'] == lagoon_removed_CWNS) & (uplist_eicodes['WERF_CODE'].str.contains(lagoon_removed_code))]\n","\n","      #if a matching row is found, set ''PRES_IND' and 'PROJ_IND' equal to 0 and update 'UP_ID_NOTE'\n","      if not CWNS_match_row.empty:\n","          uplist_eicodes.loc[CWNS_match_row.index, ['PRES_IND','PROJ_IND']] = 0\n","          uplist_eicodes.loc[CWNS_match_row.index, 'UP_ID_NOTE'] = 'Corrected based on manual check of large lagoons (2023/2024)'"]},{"cell_type":"code","execution_count":null,"id":"86d6a8ac","metadata":{"collapsed":true,"id":"86d6a8ac"},"outputs":[],"source":["#if using El Abbadi et al., 2025 method for 2022 or 2042, create a dataframe that keeps track of manual corrections\n","if (method == 'El Abbadi et al., 2025') & (scenario != 2012):\n","  #create table with manually corrected wwtps to later add UP_ID_NOTE column to treatment train assignment dataframe\n","  manual_check_ups = uplist_eicodes[['CWNS_NUM','UP_ID_NOTE']]\n","  manual_check_ups = manual_check_ups.dropna()\n","  manual_check_ups = manual_check_ups.drop_duplicates(subset = 'CWNS_NUM')"]},{"cell_type":"markdown","id":"2789de7f","metadata":{"id":"2789de7f"},"source":["# Define functions for treatment train assignment"]},{"cell_type":"code","execution_count":null,"id":"f7f9e052","metadata":{"id":"f7f9e052"},"outputs":[],"source":["def clear_old_treatment(uplist_yr_table, scenario):\n","  '''\n","  Function that removes outdated secondary/solids processes from cumulative unit process list\n","    Parameters:\n","      uplist_yr_table = dataframe of all reported unit processes relevant to treatment train assignment\n","      scenario = year for treatment train assignment (2012, 2022, or 2024)\n","    Returns:\n","      uplist_werf_yr_final = modified dataframe of reported unit processes relevant to treatment train assignment, excluding old secondary/solids treatment processes\n","  '''\n","  #extract all solids treatment processes from cumulative unit process list\n","  uplist_yr_table_dig = uplist_yr_table.loc[(uplist_yr_table['WERF_CODE'] == 'AED') | (uplist_yr_table['WERF_CODE'] == 'AND') | (uplist_yr_table['WERF_CODE'] == 'LIME') | (uplist_yr_table['WERF_CODE'] == 'FBI') | (uplist_yr_table['WERF_CODE'] == 'MHI') | (uplist_yr_table['WERF_CODE'] == 'BIODRY') | (uplist_yr_table['WERF_CODE'] == 'BS_LAGOON')]\n","\n","  #identify facilities with more than one reported solids process\n","  uplist_yr_table_dig['DUP'] = uplist_yr_table_dig.duplicated(subset = 'CWNS_NUM', keep = False)\n","  uplist_yr_table_dig_dup = uplist_yr_table_dig.loc[(uplist_yr_table_dig['DUP'] == True)]\n","\n","  #identify most recently reported solids process\n","  up_werf_dig_dup_maxyr = uplist_yr_table_dig_dup.groupby(['CWNS_NUM'])['REPORT_YEAR'].describe()[['max']]\n","  uplist_yr_table_dig_dup_keep = pd.merge(left = uplist_yr_table_dig_dup, right = up_werf_dig_dup_maxyr, how = 'left', on = 'CWNS_NUM')\n","  uplist_yr_table_dig_dup_keep.loc[(uplist_yr_table_dig_dup_keep['REPORT_YEAR'] == uplist_yr_table_dig_dup_keep['max']), 'KEEP'] = 1\n","  uplist_yr_table_dig_dup_keep.loc[(uplist_yr_table_dig_dup_keep['REPORT_YEAR'] != uplist_yr_table_dig_dup_keep['max']), 'KEEP'] = 0\n","  uplist_yr_table_dig_dup_keep = uplist_yr_table_dig_dup_keep.loc[:,['CWNS_NUM','REPORT_YEAR','WERF_CODE','KEEP']]\n","  uplist_yr_table_dig_dup_keep.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = False, inplace = True, ignore_index = True)\n","\n","  #remove less recently reported solids processes from cumulative unit process list\n","  uplist_werf_yr_cut = pd.merge(left = uplist_yr_table, right = uplist_yr_table_dig_dup_keep, how = 'left', on = ['CWNS_NUM','REPORT_YEAR','WERF_CODE'])\n","  uplist_werf_yr_cut = uplist_werf_yr_cut.loc[:,['CWNS_NUM','REPORT_YEAR',f'{scenario}_IND','WERF_CODE','KEEP']]\n","  uplist_werf_yr = uplist_werf_yr_cut.loc[(uplist_werf_yr_cut['KEEP'] != 0)]\n","  uplist_werf_yr = uplist_werf_yr.loc[:,['CWNS_NUM','REPORT_YEAR',f'{scenario}_IND','WERF_CODE']]\n","\n","  #extract all secondary treatment processes from cumulative unit process list, excluding biogas utilization, biosolids lagoons, and polishing lagoons\n","  uplist_werf_yr_sec = uplist_werf_yr.loc[(uplist_werf_yr['WERF_CODE'].str.contains('AS')) | (uplist_werf_yr['WERF_CODE'].str.contains('TF')) | (uplist_werf_yr['WERF_CODE'].str.contains('POND')) | (uplist_werf_yr['WERF_CODE'].str.contains('LAGOON'))]\n","  uplist_werf_yr_sec = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['WERF_CODE'] != 'BIOGAS_CWNS')]\n","  uplist_werf_yr_sec = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['WERF_CODE'] != 'BS_LAGOON')]\n","  uplist_werf_yr_sec = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['WERF_CODE'] != 'LAGOON_POL')]\n","\n","  #identify facilities with more than one reported secondary process\n","  uplist_werf_yr_sec['DUP'] = uplist_werf_yr_sec.duplicated(subset = 'CWNS_NUM', keep=False)\n","  uplist_werf_yr_sec_dup = uplist_werf_yr_sec.loc[(uplist_werf_yr_sec['DUP'] == True)]\n","\n","  #identify most recently reported secondary process\n","  up_werf_sec_dup_maxyr = uplist_werf_yr_sec_dup.groupby(['CWNS_NUM'])['REPORT_YEAR'].describe()[['max']]\n","  uplist_werf_yr_sec_dup_keep = pd.merge(left = uplist_werf_yr_sec_dup, right = up_werf_sec_dup_maxyr, how = 'left', on = 'CWNS_NUM')\n","  uplist_werf_yr_sec_dup_keep.loc[(uplist_werf_yr_sec_dup_keep['REPORT_YEAR'] == uplist_werf_yr_sec_dup_keep['max']), 'KEEP'] = 1\n","  uplist_werf_yr_sec_dup_keep.loc[(uplist_werf_yr_sec_dup_keep['REPORT_YEAR'] != uplist_werf_yr_sec_dup_keep['max']), 'KEEP'] = 0\n","  uplist_werf_yr_sec_dup_keep = uplist_werf_yr_sec_dup_keep.loc[:,['CWNS_NUM','REPORT_YEAR','WERF_CODE','KEEP']]\n","  uplist_werf_yr_sec_dup_keep.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = False, inplace = True, ignore_index = True)\n","\n","  #remove less recently reported secondary processes from cumulative unit process list\n","  uplist_werf_yr_cut2 = pd.merge(left = uplist_werf_yr, right = uplist_werf_yr_sec_dup_keep, how = 'left', left_on = ['CWNS_NUM', 'REPORT_YEAR', 'WERF_CODE'], right_on = ['CWNS_NUM','REPORT_YEAR','WERF_CODE'])\n","  uplist_werf_yr_cut2 = uplist_werf_yr_cut2.loc[:,['CWNS_NUM','REPORT_YEAR',f'{scenario}_IND','WERF_CODE','KEEP']]\n","  uplist_werf_yr_cut2 = uplist_werf_yr_cut2.loc[(uplist_werf_yr_cut2['KEEP'] != 0)]\n","  uplist_werf_yr_final = uplist_werf_yr_cut2.loc[:,['CWNS_NUM','REPORT_YEAR',f'{scenario}_IND','WERF_CODE']]\n","  uplist_werf_yr_final.drop_duplicates(subset = ['CWNS_NUM','WERF_CODE'], inplace = True, ignore_index = True)\n","\n","  return uplist_werf_yr_final"]},{"cell_type":"code","execution_count":null,"id":"f1fce25f","metadata":{"id":"f1fce25f"},"outputs":[],"source":["def unit_process_pivot(uplist_werf_yr_to_pivot, scenario):\n","  '''\n","  Function that groups unit processes treated equivalently in treatment train formation, then converts cumulative unit process list into a pivot table\n","    Parameters:\n","      uplist_werf_yr_to_pivot = cumulative unit process list\n","      scenario = year for treatment train assignment (2012, 2022, or 2024)\n","    Returns:\n","      tt_uppvt_yr = pivot table of active unit processes in 2022 for each wastewater treatment plant, grouped when applicable\n","  '''\n","  #create pivot table of unit processes\n","  tt_uppvt_yr = pd.pivot_table(uplist_werf_yr_to_pivot, index = 'CWNS_NUM', values = '%s_IND' %scenario, columns = 'WERF_CODE', aggfunc = np.sum, fill_value = 0)\n","\n","  #add empty columns for unit processes that were not reported in selected year\n","  all_ups = up_eicodes['WERF_CODE'].unique()\n","  reported_ups = uplist_werf_yr_to_pivot['WERF_CODE'].unique()\n","  for up in all_ups:\n","    if up not in reported_ups:\n","      tt_uppvt_yr[up] = 0\n","\n","  #group conventional activated sludge without nutrient removal\n","  tt_uppvt_yr['SUM_AS'] = tt_uppvt_yr['AS'] + tt_uppvt_yr['AS-A2O'] + tt_uppvt_yr['AS-BDENIT'] + tt_uppvt_yr['AS-EA'] + tt_uppvt_yr['AS-P'] + tt_uppvt_yr['AS-PUREO'] + tt_uppvt_yr['AS-SA']\n","  tt_uppvt_yr['BASIC_AS'] = tt_uppvt_yr['AS'] + tt_uppvt_yr['AS-EA'] + tt_uppvt_yr['AS-SA'] + tt_uppvt_yr['AS-OD'] + tt_uppvt_yr['AS-SBR']\n","  tt_uppvt_yr.loc[tt_uppvt_yr['BASIC_AS'] > 0, 'BASIC_AS'] = 1\n","\n","  #group all activated sludge with nitrogen removal\n","  tt_uppvt_yr['AS_BNR_N'] = tt_uppvt_yr['AS-A2O'] + tt_uppvt_yr['AS-BDENIT']\n","  tt_uppvt_yr.loc[tt_uppvt_yr['AS_BNR_N'] > 0, 'AS_BNR_N'] = 1\n","  tt_uppvt_yr.loc[(tt_uppvt_yr['AS'] + tt_uppvt_yr['BNR']) > 1, 'AS_BNR_N'] = 1\n","\n","  #group all trickling filters\n","  tt_uppvt_yr['TF_ALL'] = tt_uppvt_yr['TF'] + tt_uppvt_yr['TF-BF'] + tt_uppvt_yr['TF-RBC']\n","  tt_uppvt_yr.loc[tt_uppvt_yr['TF_ALL'] > 0, 'TF_ALL'] = 1\n","\n","  #group all biological phosphorous removal\n","  tt_uppvt_yr.loc[(((tt_uppvt_yr['SUM_AS'] > 0) & (tt_uppvt_yr['BIO-P'] > 0)) | (tt_uppvt_yr['AS-P'] == 1)), 'AS_BNR_P'] = 1\n","\n","  #override multiple entries to just one\n","  tt_uppvt_yr.loc[tt_uppvt_yr['PRIMARY'] > 0, 'PRIMARY'] = 1\n","  tt_uppvt_yr.loc[tt_uppvt_yr['MHI'] > 0, 'MHI'] = 1\n","  tt_uppvt_yr.loc[tt_uppvt_yr['BDENIT'] > 0, 'BDENIT'] = 1\n","\n","  #drop unnecessary columns and fill nan values with zero\n","  tt_uppvt_yr = tt_uppvt_yr.drop(['DEWATER', 'DISINF','DISINF-UV','LAGOON_POL'], axis = 1)\n","  tt_uppvt_yr = tt_uppvt_yr.fillna(0)\n","\n","  #add column with the total number of unit processes used for each wwtp\n","  tt_uppvt_yr['COUNT_UP'] = tt_uppvt_yr['AED'] + tt_uppvt_yr['AND'] + tt_uppvt_yr['BASIC_AS'] + tt_uppvt_yr['AS_BNR_N'] + tt_uppvt_yr['BDENIT'] + tt_uppvt_yr['AS_BNR_P'] + tt_uppvt_yr['BIODRY'] + tt_uppvt_yr['BIOGAS_CWNS'] + tt_uppvt_yr['BNIT'] + tt_uppvt_yr['BNR'] + tt_uppvt_yr['BS_LAGOON'] + tt_uppvt_yr['CHEM-P'] + tt_uppvt_yr['DISINF-O3'] + tt_uppvt_yr['FBI'] + tt_uppvt_yr['LAGOON'] + tt_uppvt_yr['LAGOON_AER'] + tt_uppvt_yr['LAGOON_ANAER'] + tt_uppvt_yr['LAGOON_FAC'] + tt_uppvt_yr['LAND_TRT'] + tt_uppvt_yr['LIME'] + tt_uppvt_yr['MBR-BNR'] + tt_uppvt_yr['MHI'] + tt_uppvt_yr['NIT'] + tt_uppvt_yr['STBL_POND'] + tt_uppvt_yr['TF_ALL']\n","\n","  return tt_uppvt_yr"]},{"cell_type":"code","source":["def treatment_train_werf(tt_upadd_yr, bgyr):\n","  '''\n","  Function that assigns wastewater treatment facilities with enough unit process information one or more treatment trains\n","    Parameters:\n","      tt_upadd_yr = reported unit processes for each facility in pivot table form\n","      bgyr = year which biogas systems for electricity generation are confirmed to be active\n","    Returns:\n","      tt_werf_yr = dataframe with treatment train assignments for each facility that has sufficient unit process information\n","  '''\n","  #create dataframe with treatment train assignments\n","  tt_werf_yr = tt_upadd_yr\n","\n","  def assign(name, check, exceptions = []):\n","    '''\n","    Core function which assigns a treatment train if a subset of key unit processes has been reported on or before specified year\n","      Parameters:\n","        name: treatment train to be assigned, written in Tarallo et al., 2015 naming convention\n","        check: unit processes that have to be present in order for treatment train to be assigned\n","        exceptions: unit processes and/or treatment trains that must be absent/not yet assigned in order for treatment train to be assigned\n","      Returns:\n","        tt_werf_yr = dataframe with treatment train assignments for each facility that has sufficient unit process information\n","    '''\n","    #sum the number of key unit processes present within check for a given treatment train\n","    #for given treatment train, set value equal to the sum above\n","    tt_werf_yr[name] = sum(tt_werf_yr[check[i]] for i in range(len(check)))\n","\n","    #if sum of relevant unit processes is not equal to the number of key unit processes in check, turn off treatment train\n","    tt_werf_yr.loc[tt_werf_yr[name] != len(check), name] = 0\n","\n","    #if sum of relevant unit processes is equal to the number of key unit processes in check, turn on treatment train\n","    tt_werf_yr.loc[tt_werf_yr[name] == len(check), name] = 1\n","\n","    #if exceptions exist, iterate through exceptions and turn treatment train off if one or more exceptions is met\n","    if len(exceptions) > 0:\n","        for exception in exceptions:\n","            tt_werf_yr.loc[tt_werf_yr[exception] == 1, name] = 0\n","\n","    return tt_werf_yr\n","\n","  #El Abbadi et al., 2025 method is the same as Tarallo et al., 2015, but with added treatment train configurations\n","  if method == 'El Abbadi et al., 2025':\n","    #assign treatment trains sequentially based on if all key unit processes exist and excepting unit processes/trains do not\n","    #membrane bioreactor trains\n","    assign('N1E', ['MBR-BNR','AND',f'BIOGAS_{bgyr}'])\n","    assign('N1', ['MBR-BNR','AND'],['N1E'])\n","    assign('N2', ['MBR-BNR','AED'])\n","\n","    #biological and chemical phosphorus removal trains- priority 1 within activated sludge assignment\n","    assign('H1E', ['AS_BNR_P','AND','CHEM-P',f'BIOGAS_{bgyr}'])\n","    assign('H1', ['AS_BNR_P','AND','CHEM-P'],['H1E'])\n","\n","    #biological phosphorus removal trains- priority 2 in activated sludge assignment\n","    #G train not assigned if H train has already been assigned\n","    assign('G6', ['AS_BNR_P','FBI'])\n","    assign('G5', ['AS_BNR_P','MHI'])\n","    assign('G3', ['AS_BNR_P','LIME'])\n","    assign('G2', ['AS_BNR_P','AED'])\n","    assign('G1E', ['AS_BNR_P','AND',f'BIOGAS_{bgyr}'],['H1E','H1'])\n","    assign('G1', ['AS_BNR_P','AND'], ['G1E','H1E','H1'])\n","\n","    #biological nitrogen removal trains- priority 3 in assignment\n","    #I train not assigned if H or G train has already been assigned\n","    assign('I6', ['AS_BNR_N','FBI'],['G6'])\n","    assign('I5', ['AS_BNR_N','MHI'],['G5'])\n","    assign('I3', ['AS_BNR_N','LIME'],['G3'])\n","    assign('I2', ['AS_BNR_N','AED'],['G2'])\n","    assign('I1E', ['AS_BNR_N','AND',f'BIOGAS_{bgyr}'],['H1','H1E','G1','G1E'])\n","    assign('I1', ['AS_BNR_N','AND'], ['I1E','H1','H1E','G1','G1E'])\n","\n","    #nitrification trains- priority 3 in assignment\n","    #F/E trains not assigned if H, G, or I train has already been assigned\n","    assign('F1E', ['BASIC_AS','AND','NIT',f'BIOGAS_{bgyr}'], ['AS_BNR_N','G1','G1E','H1','H1E','I1','I1E'])\n","    assign('F1', ['BASIC_AS','AND','NIT'], ['AS_BNR_N','F1E','G1','G1E','H1','H1E','I1','I1E'])\n","    assign('E2P', ['BASIC_AS','AED','NIT','PRIMARY'], ['AS_BNR_N','G2','I2'])\n","    assign('E2', ['BASIC_AS','AED','NIT'], ['AS_BNR_N','G2','I2','E2P'])\n","\n","    #pure oxygen activated sludge trains- priority 4 in activated sludge assignment\n","    #O train not assigned if E, F, H, G, or I train has already been assigned\n","    assign('O5', ['AS-PUREO','MHI'],['G5','I5'])\n","    assign('O6', ['AS-PUREO','FBI'],['G6','I6'])\n","    assign('O3', ['AS-PUREO','LIME'],['G3','I3'])\n","    assign('O2', ['AS-PUREO','AED'],['G2','I2','E2','E2P'])\n","    assign('O1E', ['AS-PUREO','AND',f'BIOGAS_{bgyr}'],['F1','F1E','G1E','G1','I1','I1E','H1','H1E'])\n","    assign('O1', ['AS-PUREO','AND'], ['F1','F1E','O1E','G1E','G1','I1','I1E','H1','H1E'])\n","\n","    #trickling filter trains\n","    #D train assignment can exist in multiple treatment trains alongside activated sludge systems\n","    assign('D5', ['TF_ALL','MHI'])\n","    assign('D6', ['TF_ALL','FBI'])\n","    assign('D3', ['TF_ALL','LIME'])\n","    assign('D2', ['TF_ALL','AED'])\n","    assign('D1E', ['TF_ALL','AND',f'BIOGAS_{bgyr}'])\n","    assign('D1', ['TF_ALL','AND'],['D1E'])\n","\n","    #basic activated sludge, primary trains- priority 5 in activated sludge assignment\n","    #B train not assigned if O, E, F, H, G, or I train has already been assigned\n","    assign('B6', ['BASIC_AS','FBI','PRIMARY'], ['G6','I6','O6'])\n","    assign('B5', ['BASIC_AS','MHI','PRIMARY'], ['AS-PUREO','G5','I5','O5'])\n","    assign('B4', ['BASIC_AS','AND','BIODRY','PRIMARY'])\n","    assign('B3', ['BASIC_AS','LIME','PRIMARY'], ['G3','I3','O3'])\n","    assign('B2', ['BASIC_AS','AED','PRIMARY'], ['E2','E2P','G2','I2','N2','O2'])\n","    assign('B1E', ['BASIC_AS','AND','PRIMARY',f'BIOGAS_{bgyr}'],['AS_BNR_N','AS-PUREO','B4','F1','F1E','G1','G1E','H1','H1E','I1','I1E','N1','N1E','O1','O1E'])\n","    assign('B1', ['BASIC_AS','AND','PRIMARY'], ['AS_BNR_N','AS-PUREO','B1E','B4','F1','F1E','G1','G1E','H1','H1E','I1','I1E','N1','N1E','O1','O1E'])\n","\n","    #basic activated sludge trains- priority 6 in activated sludge assignment\n","    #B train not assigned if B, O, E, F, H, G, or I train has already been assigned\n","    assign('C5', ['BASIC_AS','MHI'], ['B5','G5','I5','O5'])\n","    assign('C6', ['BASIC_AS','FBI'], ['B6','G6','I6','O6'])\n","    assign('C3', ['BASIC_AS','LIME'], ['B3','G3','I3','O3'])\n","    assign('C2', ['BASIC_AS','AED'], ['B2','E2','E2P','G2','I2','N2','O2'])\n","    assign('C1E', ['BASIC_AS','AND',f'BIOGAS_{bgyr}'], ['B1','B1E','B4','F1','F1E','G1','G1E','H1','H1E','I1E','I1','N1E','N1','O1','O1E'])\n","    assign('C1', ['BASIC_AS','AND'], ['B1','B1E','B4','C1E','F1','F1E','G1','G1E','H1','H1E','I1','I1E','N1','N1E','O1','O1E'])\n","\n","    #identify the number of treatment trains assigned for each facility in the first round of assignment\n","    tt_werf_yr['TT_IDENTIFIED'] = sum(tt_werf_yr[i] for i in ('LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','STBL_POND','I1E','G6','I6','O5','O6','O3','O1E','G5','I5','C5','C6','O2','O1','N1','N1E','N2','I3','I2','I1','H1','H1E','G3','G2','G1','G1E','F1','F1E','E2','E2P','D5','D6','D1','D1E','D3','D2','C3','C2','C1','C1E','B6','B5','B4','B3','B1E','B1','B2'))\n","\n","    #for treatment trains that were identified using reported unit processes, add a note\n","    tt_werf_yr.loc[tt_werf_yr['TT_IDENTIFIED'] > 0, 'TT_ASSIGN_NOTE'] = 'Assigned based on reported unit processes'\n","\n","  #the original Tarallo et al., 2015 method provides energy intensities for only a subset of treatment trains in the U.S.\n","  elif method == 'Tarallo et al., 2015':\n","    #assign treatment trains sequentially based on if all key unit processes exist and excepting unit processes/trains do not\n","    #membrane bioreactor trains\n","    assign('N1', ['MBR-BNR','AND'])\n","    assign('N2', ['MBR-BNR','AED'])\n","\n","    #biological and chemical phosphorus removal trains- priority 1 within activated sludge assignment\n","    assign('H1', ['AS_BNR_P','AND','CHEM-P'])\n","\n","    #biological phosphorus removal trains- priority 2 in activated sludge assignment\n","    #G train not assigned if an H train has already been assigned\n","    assign('G1E', ['AS_BNR_P','AND',f'BIOGAS_{bgyr}'],['H1'])\n","    assign('G1', ['AS_BNR_P','AND'], ['G1E','H1'])\n","\n","    #biological nitrogen removal trains- priority 3 in assignment\n","    #I train not assigned if H or G train has already been assigned\n","    assign('I3', ['AS_BNR_N','LIME'])\n","    assign('I2', ['AS_BNR_N','AED'])\n","\n","    #nitrification trains- priority 3 in assignment\n","    #F/E trains not assigned if H, G, or I train has already been assigned\n","    assign('F1', ['BASIC_AS','AND','NIT'], ['AS_BNR_N','G1','G1E','H1'])\n","    assign('E2P', ['BASIC_AS','AED','NIT','PRIMARY'], ['AS_BNR_N','I2'])\n","    assign('E2', ['BASIC_AS','AED','NIT'], ['AS_BNR_N','I2','E2P'])\n","\n","    #pure oxygen activated sludge trains- priority 4 in activated sludge assignment\n","    #O train not assigned if E, F, H, G, or I train has already been assigned\n","    assign('O1', ['AS-PUREO','AND'], ['F1','G1E','G1','H1'])\n","\n","    #trickling filter trains\n","    #D train assignment can exist in multiple treatment trains alongside activated sludge systems\n","    assign('D1', ['TF_ALL','AND'])\n","\n","    #basic activated sludge, primary trains- priority 5 in activated sludge assignment\n","    #B train not assigned if O, E, F, H, G, or I train has already been assigned\n","    assign('B6', ['BASIC_AS','FBI','PRIMARY'])\n","    assign('B5', ['BASIC_AS','MHI','PRIMARY'], ['AS-PUREO'])\n","    assign('B4', ['BASIC_AS','AND','BIODRY','PRIMARY'])\n","    assign('B1E', ['BASIC_AS','AND','PRIMARY',f'BIOGAS_{bgyr}'],['AS_BNR_N','AS-PUREO','B4','F1','G1','G1E','H1','N1','O1'])\n","    assign('B1', ['BASIC_AS','AND','PRIMARY'], ['AS_BNR_N','AS-PUREO','B1E','B4','F1','G1','G1E','H1','N1','O1'])\n","\n","    #basic activated sludge trains- priority 6 in activated sludge assignment\n","    #B train not assigned if B, O, E, F, H, G, or I train has already been assigned\n","    assign('C3', ['BASIC_AS','LIME'], ['I3'])\n","\n","    #identify the number of treatment trains assigned for each facility in the first round of assignment\n","    tt_werf_yr['TT_IDENTIFIED'] = sum(tt_werf_yr[i] for i in ('LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','STBL_POND','O1','N1','N2','I3','I2','H1','G1','G1E','F1','E2','E2P', 'D1','C3','B6','B5','B4','B1E','B1'))\n","\n","    #for treatment trains that were identified using reported unit processes, add a note\n","    tt_werf_yr.loc[tt_werf_yr['TT_IDENTIFIED'] > 0, 'TT_ASSIGN_NOTE'] = 'Assigned based on reported unit processes'\n","\n","  else:\n","    print('Method not recognized')\n","\n","  return tt_werf_yr"],"metadata":{"id":"Ap1mQTFRcLqP"},"id":"Ap1mQTFRcLqP","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"PdWe7FtFd8lG","metadata":{"id":"PdWe7FtFd8lG"},"source":["# Assign treatment trains"]},{"cell_type":"code","execution_count":null,"id":"7b15c46a","metadata":{"id":"7b15c46a","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d88e5cee-488b-4dda-c66b-b2e925c4fde6","executionInfo":{"status":"ok","timestamp":1767636935979,"user_tz":480,"elapsed":9728,"user":{"displayName":"Abigayle Hodson","userId":"02880304820331263887"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-796885096.py:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  uplist_yr_table_dig['DUP'] = uplist_yr_table_dig.duplicated(subset = 'CWNS_NUM', keep = False)\n","/tmp/ipython-input-4226594610.py:11: FutureWarning: The provided callable <function sum at 0x7b8e4836a7a0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n","  tt_uppvt_yr = pd.pivot_table(uplist_werf_yr_to_pivot, index = 'CWNS_NUM', values = '%s_IND' %scenario, columns = 'WERF_CODE', aggfunc = np.sum, fill_value = 0)\n"]}],"source":["#create columns that indicate if a unit process was present in 2012, 2022, or 2042\n","uplist_eicodes.loc[(uplist_eicodes['REPORT_YEAR'] <= 2012) & (uplist_eicodes['PRES_IND'] == 1), '2012_IND'] = 1\n","uplist_eicodes.loc[(uplist_eicodes['REPORT_YEAR'] <= 2022) & (uplist_eicodes['PRES_IND'] == 1), '2022_IND'] = 1\n","uplist_eicodes.loc[(uplist_eicodes['PRES_IND'] == 1) | (uplist_eicodes['PROJ_IND'] == 1), '2042_IND'] = 1\n","\n","#filter unit process list to unit processes that were present in selected scenario\n","uplist_werf_scenario = uplist_eicodes.loc[(uplist_eicodes[f'{str(scenario)}_IND'] == 1)][['CWNS_NUM','REPORT_YEAR',f'{str(scenario)}_IND','WERF_CODE']]\n","uplist_werf_scenario = uplist_werf_scenario.dropna(subset = ['WERF_CODE'])\n","\n","#retain only most recently reported secondary/solids processes\n","uplist_werf_scenario.sort_values(by = ['CWNS_NUM','REPORT_YEAR'], ascending = True, inplace = True, ignore_index = True)\n","uplist_werf_scenario_final = clear_old_treatment(uplist_werf_scenario, str(scenario))\n","\n","#create a pivot table describing all the unit processes active at each wwtp for selected year\n","tt_uppvt_scenario = unit_process_pivot(uplist_werf_scenario_final, str(scenario))"]},{"cell_type":"code","execution_count":null,"id":"daa499b7","metadata":{"id":"daa499b7"},"outputs":[],"source":["#filter main wwtp dataframe to relevant columns\n","if (scenario == 2012) | (scenario == 2022):\n","  wwtps_trt_scenario = wwtps[['CWNS_NUM','EPA_REGION','PRES_AMMONIA_REMOVAL','PRES_NITROGEN_REMOVAL','PRES_PHOSPHOROUS_REMOVAL',f'BIOGAS_{str(scenario)}',f'{str(scenario)}_FLOW_MGD',f'{str(scenario)}_FLOW_CAT_MGD']]\n","else:\n","  wwtps_trt_scenario = wwtps[['CWNS_NUM','EPA_REGION','PROJ_AMMONIA_REMOVAL','PROJ_NITROGEN_REMOVAL','PROJ_PHOSPHOROUS_REMOVAL',f'BIOGAS_{str(scenario)}',f'{str(scenario)}_FLOW_MGD',f'{str(scenario)}_FLOW_CAT_MGD']].rename(columns = {'PROJ_AMMONIA_REMOVAL':'PRES_AMMONIA_REMOVAL','PROJ_NITROGEN_REMOVAL':'PRES_NITROGEN_REMOVAL','PROJ_PHOSPHOROUS_REMOVAL':'PRES_PHOSPHOROUS_REMOVAL'})\n","\n","#merge unit process list and facility info tables; replace nan values with 0\n","tt_upadd_scenario = pd.merge(left = tt_uppvt_scenario, right = wwtps_trt_scenario, how = 'right', on = 'CWNS_NUM')\n","tt_upadd_scenario = tt_upadd_scenario.fillna(0)\n","\n","#use the ammonia/nitrogen/phosphorous removal flags provided in the 2012 CWNS to add nutrient removal processes to unit process list\n","#NIT_FLAG column is just used for tracking which nitrification unit processes were added via the PRES_AMMONIA_REMOVAL column\n","tt_upadd_scenario.loc[tt_upadd_scenario['PRES_AMMONIA_REMOVAL'] == 'Y', 'NIT'] = 1\n","tt_upadd_scenario.loc[tt_upadd_scenario['PRES_AMMONIA_REMOVAL'] == 'Y', 'NIT_FLAG'] = 1\n","tt_upadd_scenario.loc[tt_upadd_scenario['PRES_NITROGEN_REMOVAL'] == 'Y', 'BNR'] = 1\n","tt_upadd_scenario.loc[tt_upadd_scenario['PRES_PHOSPHOROUS_REMOVAL'] == 'Y', 'P_REMOVAL'] = 1\n","\n","#assume all phosphorus removal not specified as biological is done using chemical processes\n","tt_upadd_scenario.loc[(tt_upadd_scenario['AS_BNR_P'] == 0) & (tt_upadd_scenario['BIO-P'] == 0) & (tt_upadd_scenario['P_REMOVAL'] == 1), 'CHEM-P'] = 1\n","\n","#filter to relevant columns\n","tt_upadd_scenario = tt_upadd_scenario[['CWNS_NUM','AED','AND','AS','AS-A2O','AS-BDENIT','AS-EA','AS-OD','AS-P','AS-PUREO','AS-SA','AS-SBR','BDENIT','BIO-P','BIODRY','BIOGAS_CWNS','BNIT','BNR','BS_LAGOON','CHEM-P','DISINF-O3','FBI','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','LAND_TRT','LIME','MBR-BNR','MHI','NIT','NIT_FLAG','PRIMARY','STBL_POND','TF','TF-BF','TF-RBC','SUM_AS','TF_ALL','BASIC_AS','AS_BNR_N','AS_BNR_P','COUNT_UP',f'BIOGAS_{str(scenario)}',f'{str(scenario)}_FLOW_MGD',f'{str(scenario)}_FLOW_CAT_MGD','EPA_REGION']]"]},{"cell_type":"code","execution_count":null,"id":"ee9ce035","metadata":{"collapsed":true,"id":"ee9ce035","scrolled":true},"outputs":[],"source":["#for wwtps with sufficient unit process data, assign treatment trains\n","ttwerf_scenario = treatment_train_werf(tt_upadd_scenario, scenario)\n","\n","#filter to relevant columns based on what treatment trains were assigned\n","if method == 'El Abbadi et al., 2025':\n","  ttwerf_scenario = ttwerf_scenario[['CWNS_NUM','AED','AND','AS','AS-A2O','AS-BDENIT','AS-EA','AS-OD','AS-P','AS-PUREO','AS-SA','AS-SBR','BDENIT','BIO-P','BIODRY','BNIT','BNR','BS_LAGOON','CHEM-P','DISINF-O3','FBI','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','LAND_TRT','LIME','MBR-BNR','MHI','NIT','NIT_FLAG','PRIMARY','STBL_POND','TF','TF-BF','TF-RBC','SUM_AS','TF_ALL','BASIC_AS','AS_BNR_N','AS_BNR_P','COUNT_UP',f'BIOGAS_{str(scenario)}',f'{str(scenario)}_FLOW_MGD',f'{str(scenario)}_FLOW_CAT_MGD','C1','C1E','C2','C3','C5','C6','B1','B1E','B2','B3','B4','B5','B6','D1','D1E','D2','D3','D5','D6','E2','E2P','F1','F1E','G1','G1E','G2','G3','G5','G6','H1','H1E','I1','I1E','I2','I3','I5','I6','N1','N1E','N2','O1','O1E','O2','O3','O5','O6','TT_IDENTIFIED','TT_ASSIGN_NOTE','EPA_REGION']]\n","else:\n","  ttwerf_scenario = ttwerf_scenario[['CWNS_NUM','AED','AND','AS','AS-A2O','AS-BDENIT','AS-EA','AS-OD','AS-P','AS-PUREO','AS-SA','AS-SBR','BDENIT','BIO-P','BIODRY','BNIT','BNR','BS_LAGOON','CHEM-P','DISINF-O3','FBI','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','LAND_TRT','LIME','MBR-BNR','MHI','NIT','NIT_FLAG','PRIMARY','STBL_POND','TF','TF-BF','TF-RBC','SUM_AS','TF_ALL','BASIC_AS','AS_BNR_N','AS_BNR_P','COUNT_UP',f'BIOGAS_{str(scenario)}',f'{str(scenario)}_FLOW_MGD',f'{str(scenario)}_FLOW_CAT_MGD','C3','B1','B1E','B4','B5','B6','D1','E2','E2P','F1','G1','G1E','H1','I2','I3','N1','N2','O1','TT_IDENTIFIED','TT_ASSIGN_NOTE','EPA_REGION']]\n","\n","#for treatment O1 trains that have nitrification, switch to F1\n","index = ttwerf_scenario.loc[(ttwerf_scenario['O1'] == 1) & (ttwerf_scenario['NIT'] == 1)].index\n","for i in index:\n","  ttwerf_scenario.at[i,'F1'] = 1\n","  ttwerf_scenario.at[i,'O1'] = 0\n","\n","if method == 'El Abbadi et al., 2025':\n","  #for treatment O1E trains that have nitrification, switch to F1E\n","  index2 = ttwerf_scenario.loc[(ttwerf_scenario['O1E'] == 1) & (ttwerf_scenario['NIT'] == 1)].index\n","  for i in index2:\n","    ttwerf_scenario.at[i,'F1E'] = 1\n","    ttwerf_scenario.at[i,'O1E'] = 0"]},{"cell_type":"code","source":["#based on the facilities that were assigned a treatment train based solely on reported unit process information, create a dataframe that contains both the most common treatment train overall and the most common treatment train with a key unit process present for all possible EPA region / plant size combinations. This dataframe is later used to make treatment train assignments for facilities with limited unit process information.\n","\n","#manually assign Boston WWTP a treatment train if using Tarallo et al. method- messes up most_common dataframe otherwise\n","if method == 'Tarallo et al., 2015':\n","  ttwerf_scenario.loc[ttwerf_scenario['CWNS_NUM'] == '25000128001', 'B1E'] = 1\n","  ttwerf_scenario.loc[ttwerf_scenario['CWNS_NUM'] == '25000128001', 'TT_ASSIGN_NOTE'] = 'Manually assigned because this plant is the only one in EPA region 1 > 100 MGD'\n","  ttwerf_scenario.loc[ttwerf_scenario['CWNS_NUM'] == '25000128001', 'TT_IDENTIFIED'] = 1\n","\n","#create a dataframe of all the wwtps that were assigned a treatment train based purely on reported unit processes\n","assigned = ttwerf_scenario.loc[ttwerf_scenario['TT_IDENTIFIED'] != 0]\n","assigned.reset_index(inplace = True, drop = True)\n","\n","if method == 'El Abbadi et al., 2025':\n","  #create combined columns for 1 and 1E trains\n","  assigned['B1B1E'] = assigned['B1'] + assigned['B1E']\n","  assigned['G1G1E'] = assigned['G1'] + assigned['G1E']\n","  assigned['C1C1E'] = assigned['C1'] + assigned['C1E']\n","  assigned['D1D1E'] = assigned['D1'] + assigned['D1E']\n","  assigned['F1F1E'] = assigned['F1'] + assigned['F1E']\n","  assigned['H1H1E'] = assigned['H1'] + assigned['H1E']\n","  assigned['I1I1E'] = assigned['I1'] + assigned['I1E']\n","  assigned['N1N1E'] = assigned['N1'] + assigned['N1E']\n","  assigned['O1O1E'] = assigned['O1'] + assigned['O1E']\n","\n","  #filter to relevant columns\n","  assigned = assigned[[f'{str(scenario)}_FLOW_CAT_MGD','EPA_REGION','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','STBL_POND','C1C1E', 'C2', 'C3', 'C5','C6', 'B1B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1D1E', 'D2', 'D3', 'D5','D6', 'E2', 'E2P', 'F1F1E','G1G1E', 'G2', 'G3', 'G5', 'G6', 'H1H1E','I1I1E', 'I2', 'I3', 'I5', 'I6', 'N1N1E','N2', 'O1O1E', 'O2','O3', 'O5', 'O6']]\n","\n","  #define list of key unit processes and the treatment trains they are present within\n","  key_ups = {'BASIC_AS':['F1F1E','E2P','E2','B6','B5','B4','B3','B2','B1B1E','C5','C6','C3','C2','C1C1E'],'AS_BNR_N':['H1H1E','G6','G5','G3','G2','G1G1E'],'AS-PUREO':['O5','O6','O3','O2','O1O1E'],'AND':['O1O1E','N1N1E','H1H1E','G1G1E','I1I1E','F1F1E','D1D1E','B1B1E','C1C1E'],'AED':['O2','N2','G2','I2','E2P','E2','D2','B2','C2'],'LIME':['O3','G3','I3','D3','B3','C3'],'FBI':['O6','G6','I6','D6','B6','C6'],'MHI':['O5','G5','I5','D5','B5','C5'],'TF_ALL':['D5','D6','D3','D1D1E'],'NIT':['E2','E2P','F1F1E'], 'AS_BNR_P':['I6','I5','I3','I2','I1I1E']}\n","\n","else:\n","  #create combined columns for 1 and 1E trains\n","  assigned['B1B1E'] = assigned['B1'] + assigned['B1E']\n","  assigned['G1G1E'] = assigned['G1'] + assigned['G1E']\n","\n","  #filter to relevant columns\n","  assigned = assigned[[f'{str(scenario)}_FLOW_CAT_MGD','EPA_REGION','LAGOON','LAGOON_AER','LAGOON_ANAER','LAGOON_FAC','STBL_POND','C3','B1B1E', 'B4', 'B5', 'B6', 'D1','E2', 'E2P', 'F1','G1G1E', 'H1','I2', 'I3', 'N1','N2', 'O1']]\n","\n","  #define list of key unit processes and the treatment trains they are present within\n","  key_ups = {'BASIC_AS':['F1','E2P','E2','B6','B5','B4','B1B1E','C3'],'AS_BNR_N':['H1','G1G1E'],'AS-PUREO':['O1'],'AND':['O1','N1','H1','G1G1E','F1','D1','B1B1E'],'AED':['N2','I2','E2P','E2'],'LIME':['I3','C3'],'FBI':['B6'],'MHI':['B5'],'TF_ALL':['D1'],'NIT':['E2','E2P','F1'], 'AS_BNR_P':['I3','I2']}\n","\n","#group assigned trains by EPA region and plant size\n","most_common = assigned.groupby([f'{str(scenario)}_FLOW_CAT_MGD', 'EPA_REGION']).sum()\n","\n","#create fields for the most common treatment train per EPA region / plant size overall and for just trains with key unit processes present\n","most_common['Most Common TT (OVERALL)'] = np.nan\n","most_common['Most Common TT (BASIC_AS)'] = np.nan\n","most_common['Most Common TT (AS_BNR_N)'] = np.nan\n","most_common['Most Common TT (AS-PUREO)'] = np.nan\n","most_common['Most Common TT (AND)'] = np.nan\n","most_common['Most Common TT (AED)'] = np.nan\n","most_common['Most Common TT (LIME)'] = np.nan\n","most_common['Most Common TT (FBI)'] = np.nan\n","most_common['Most Common TT (MHI)'] = np.nan\n","most_common['Most Common TT (TF_ALL)'] = np.nan\n","most_common['Most Common TT (NIT)'] = np.nan\n","most_common['Most Common TT (AS_BNR_P)'] = np.nan\n","\n","#iterate through each EPA region / plant size combinations\n","for index, row in most_common.iterrows():\n","  #identify most common treatment train for region / plant size\n","  if row.max() != 0:\n","    #if there are no ties for most common treatment train\n","    if (row == row.max()).sum() == 1:\n","      most_common.at[index, 'Most Common TT (OVERALL)'] = row[row == row.max()].index.values[0]\n","    #if there are ties for the most common treatment train, separate with a slash\n","    else:\n","      most_common.at[index, 'Most Common TT (OVERALL)'] = '/'.join(row[row == row.max()].index.values.tolist())\n","  #iterate through key unit processes\n","  for key_up in key_ups:\n","    #identify treatment trains that contain that key unit process\n","    relevant_tts = key_ups[key_up]\n","    #identify the most common treatment train within relevant subset\n","    if row[relevant_tts].max() != 0:\n","      #if there are no ties for most common treatment train\n","      if (row[relevant_tts] == row[relevant_tts].max()).sum() == 1:\n","        most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","      #if there are ties for the most common treatment train, separate with a slash\n","      else:\n","        most_common.at[index, ('Most Common TT (' + key_up +')')] = '/'.join(row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values.tolist())\n","\n","#if there are no facilities w/ key nutrient removal process in the size/region combination, override with most common treatment train containing key unit process across all EPA regions and size categories\n","for index, row in most_common.iterrows():\n","  for key_up in ['AS_BNR_P','NIT','AS_BNR_N']:\n","    if pd.isna(row['Most Common TT (' + key_up +')']):\n","      lst = list(most_common['Most Common TT (' + key_up +')'].dropna().values)\n","      most_common.at[index, 'Most Common TT (' + key_up +')'] = max(set(lst), key=lst.count)\n","\n","#in the 'Most Common TT' columns, replace B1B1E with B1, C1C1E with C1, etc. to ensure that electricity-producing trains are not assigned as most common trains\n","if method == 'El Abbadi et al., 2025':\n","  most_common = most_common.replace({'B1B1E':'B1','C1C1E':'C1','D1D1E': 'D1','F1F1E': 'F1','G1G1E': 'G1','H1H1E': 'H1','I1I1E': 'I1','N1N1E':'N1','O1O1E':'O1'}, regex=True)\n","else:\n","  most_common = most_common.replace({'B1B1E':'B1','G1G1E': 'G1'}, regex=True)"],"metadata":{"id":"Vhi5fAPVQApN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767636937347,"user_tz":480,"elapsed":1276,"user":{"displayName":"Abigayle Hodson","userId":"02880304820331263887"}},"outputId":"759355ab-d8af-4817-84ea-f5d7bfd3c599"},"id":"Vhi5fAPVQApN","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2257886283.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  assigned['B1B1E'] = assigned['B1'] + assigned['B1E']\n","/tmp/ipython-input-2257886283.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  assigned['G1G1E'] = assigned['G1'] + assigned['G1E']\n","/tmp/ipython-input-2257886283.py:65: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B1B1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, 'Most Common TT (OVERALL)'] = row[row == row.max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B1B1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B1B1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'G1G1E' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B5' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'F1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'O1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'D1' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'C3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'E2' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'B6' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n","/tmp/ipython-input-2257886283.py:77: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'I3' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n","  most_common.at[index, ('Most Common TT (' + key_up +')')] = row[relevant_tts][row[relevant_tts] == row[relevant_tts].max()].index.values[0]\n"]}]},{"cell_type":"code","execution_count":null,"id":"6lSHklYBsUlV","metadata":{"id":"6lSHklYBsUlV"},"outputs":[],"source":["#for unassigned treatment trains that contain key unit processes ('BASIC_AS, 'AS_BNR_N','AS_BNR_P','AS_PUREO','AND','AED','LIME','FBI','MHI','TF_ALL',and 'NIT'), assign a treatment train based on the most common train for that size/region that includes that key unit process\n","if assign_missing_facilities == True:\n","  #identify wwtps that do not yet have an assigned treatment train\n","  no_tt = ttwerf_scenario.loc[ttwerf_scenario['TT_IDENTIFIED'] == 0].reset_index(drop = True)\n","\n","  #define list of key unit processes\n","  key_ups = ['BASIC_AS','AS_BNR_N','AS_BNR_P','AS-PUREO','AND','AED','LIME','FBI','MHI','TF_ALL','NIT']\n","\n","  #for specific unit processes (AS_BNR_P, AS_BNR_N, NIT, AS_PUREO, BASIC_AS), if one is present, turn off less important unit processes\n","  #e.g., if AS_BNR_P is present, turn off AS_BNR_N, NIT, AS_PUREO, BASIC_AS; if AS_BNR_N is present, turn off NIT, AS_PUREO, BASIC_AS, etc.\n","  for index, row in no_tt.iterrows():\n","    if row['AS_BNR_P'] == 1:\n","      no_tt.at[index, 'AS_BNR_N'] = 0\n","      no_tt.at[index, 'NIT'] = 0\n","      no_tt.at[index, 'AS-PUREO'] = 0\n","      no_tt.at[index, 'BASIC_AS'] = 0\n","    elif row['AS_BNR_N'] == 1:\n","      no_tt.at[index, 'NIT'] = 0\n","      no_tt.at[index, 'AS-PUREO'] = 0\n","      no_tt.at[index, 'BASIC_AS'] = 0\n","    elif row['NIT'] == 1:\n","      no_tt.at[index, 'AS-PUREO'] = 0\n","      no_tt.at[index, 'BASIC_AS'] = 0\n","    elif row['AS-PUREO'] == 1:\n","      no_tt.at[index, 'BASIC_AS'] = 0\n","\n","  #iterate through wwtps without an assigned treatment train\n","  for index, row in no_tt.iterrows():\n","    #identify size and EPA region of current wwtp\n","    size = row[f'{str(scenario)}_FLOW_CAT_MGD']\n","    region = row['EPA_REGION']\n","    #check for key unit processes in current wwtp\n","    for up in key_ups:\n","      if row[up] > 0:\n","        #identify most common treatment train for plants of a similar size, region, and key unit process\n","        tt_common = most_common.at[(size,region),('Most Common TT (' + up + ')')]\n","        #turn on treatment train in no_tt dataframe\n","        if pd.isna(tt_common) == False:\n","          #if only one treatment train was identified\n","          if '/' not in tt_common:\n","            #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n","            if (row['NIT'] == 1) & (tt_common[0] == 'B' or tt_common[0] == 'C'):\n","              tt_common = np.nan\n","            else:\n","              no_tt.at[index, tt_common] = 1\n","              no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n","              no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on partial unit process information based on common treatment trains of similar size in EPA region'\n","          #if multiple treatment trains were identified, split into multiple strings before turning on treatment trains in no_tt dataframe\n","          else:\n","            tt_common_multiple = tt_common.split('/')\n","            for tt in tt_common_multiple:\n","              #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n","              if (row['NIT'] == 1) & (tt[0] == 'B' or tt[0] == 'C'):\n","                tt_common = np.nan\n","              else:\n","                no_tt.at[index, tt] = 1\n","                no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n","                no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on partial unit process information based on common treatment trains of similar size in EPA region'\n","\n","  #add original unit processes back into the no_tt dataframe\n","  original_ups = ttwerf_scenario.loc[ttwerf_scenario['TT_IDENTIFIED'] == 0].reset_index(drop = True)[['CWNS_NUM', 'AED', 'AND', 'AS', 'AS-A2O', 'AS-BDENIT','AS-EA', 'AS-OD', 'AS-P', 'AS-PUREO', 'AS-SA', 'AS-SBR', 'BDENIT','BIO-P', 'BIODRY', 'BNIT', 'BNR', 'BS_LAGOON', 'CHEM-P','DISINF-O3', 'FBI', 'LAGOON', 'LAGOON_AER', 'LAGOON_ANAER','LAGOON_FAC', 'LAND_TRT', 'LIME', 'MBR-BNR', 'MHI', 'NIT', 'NIT_FLAG','PRIMARY', 'STBL_POND', 'TF', 'TF-BF', 'TF-RBC', 'SUM_AS', 'TF_ALL','BASIC_AS', 'AS_BNR_N', 'AS_BNR_P']]\n","\n","  if method == 'El Abbadi et al., 2025':\n","    new_tts = no_tt[['COUNT_UP', f'BIOGAS_{str(scenario)}', f'{str(scenario)}_FLOW_MGD', f'{str(scenario)}_FLOW_CAT_MGD', 'EPA_REGION', 'C1', 'C1E', 'C2', 'C3', 'C5', 'C6', 'B1', 'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E', 'D2', 'D3', 'D5', 'D6', 'E2', 'E2P', 'F1', 'F1E', 'G1', 'G1E', 'G2', 'G3', 'G5', 'G6', 'H1', 'H1E', 'I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6', 'TT_IDENTIFIED', 'TT_ASSIGN_NOTE']]\n","  else:\n","    new_tts = no_tt[['COUNT_UP', f'BIOGAS_{str(scenario)}', f'{str(scenario)}_FLOW_MGD', f'{str(scenario)}_FLOW_CAT_MGD', 'EPA_REGION', 'C3', 'B1', 'B1E', 'B4', 'B5', 'B6', 'D1', 'E2', 'E2P', 'F1', 'G1', 'G1E', 'H1','I2', 'I3','N1', 'N2', 'O1', 'TT_IDENTIFIED', 'TT_ASSIGN_NOTE']]\n","\n","  no_tt = pd.concat([original_ups, new_tts], axis = 1)\n","\n","  #merge new assignments based on partial unit process information back into main dataframe\n","  ttwerf_scenario = ttwerf_scenario.loc[ttwerf_scenario['TT_IDENTIFIED'] != 0]\n","  ttwerf_scenario = pd.concat([ttwerf_scenario, no_tt], axis = 0)"]},{"cell_type":"code","execution_count":null,"id":"a1e18616","metadata":{"id":"a1e18616"},"outputs":[],"source":["#for remaining wwtps without a treatment train assignment, assign a treatment train using the most common treatment train of that size/region (ignoring production of energy from biogas)\n","if assign_missing_facilities == True:\n","  #identify wwtps without a treatment train assignment or any key unit processes\n","  no_tt = ttwerf_scenario.loc[ttwerf_scenario['TT_IDENTIFIED'] == 0].reset_index(drop = True)\n","\n","  #iterate through wwtps without an assigned treatment train\n","  for index, row in no_tt.iterrows():\n","    #identify size and EPA region of current wwtp\n","    size = row[f'{str(scenario)}_FLOW_CAT_MGD']\n","    region = row['EPA_REGION']\n","    #identify most common treatment train for plants of a similar size and region\n","    tt_common = most_common.at[(size,region),('Most Common TT (OVERALL)')]\n","    #turn on treatment train in no_tt dataframe\n","    if pd.isna(tt_common) == False:\n","      #if only one treatment train was identified\n","      if '/' not in tt_common:\n","        #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n","        if (row['NIT'] == 1) & (tt_common[0] == 'B' or tt_common[0] == 'C'):\n","          tt_common = np.nan\n","        else:\n","          no_tt.at[index, tt_common] = 1\n","          no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n","          no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on common treatment trains of similar size in EPA region'\n","      #if multiple treatment trains were identified, split into multiple strings before turning on treatment trains in no_tt dataframe\n","      else:\n","        tt_common_multiple = tt_common.split('/')\n","        for tt in tt_common_multiple:\n","          #if most common treatment train is a conventional activated sludge train, but the nitrification flag is on, override tt_common to nan\n","          if (row['NIT'] == 1) & (tt[0] == 'B' or tt[0] == 'C'):\n","            tt = np.nan\n","          else:\n","            no_tt.at[index, tt] = 1\n","            no_tt.at[index, 'TT_IDENTIFIED'] = no_tt.at[index,'TT_IDENTIFIED'] + 1\n","            no_tt.at[index, 'TT_ASSIGN_NOTE'] = 'Assigned based on common treatment trains of similar size in EPA region'\n","\n","  #merge new assignments back into main dataframe\n","  ttwerf_scenario = ttwerf_scenario.loc[ttwerf_scenario['TT_IDENTIFIED'] != 0]\n","  ttwerf_scenario = pd.concat([ttwerf_scenario, no_tt], axis = 0)"]},{"cell_type":"code","execution_count":null,"id":"KtKDMzVpkhR_","metadata":{"id":"KtKDMzVpkhR_"},"outputs":[],"source":["#if manual corrections were made to unit process list, add a notes column detailing edits\n","if (method == 'El Abbadi et al., 2025') & (scenario != 2012):\n","  tt_werf_scenario_final = pd.merge(left = ttwerf_scenario, right = manual_check_ups, how = 'left', on = 'CWNS_NUM')\n","else:\n","  tt_werf_scenario_final = ttwerf_scenario"]},{"cell_type":"code","source":["#identify facilities that reported using biogas to generate electricity in the DOE or WEF databases that were not assigned an electricity-generating treatment train\n","if (method == 'El Abbadi et al., 2025') & (scenario != 2012):\n","  biogas_tts = tt_werf_scenario_final.loc[tt_werf_scenario_final[f'BIOGAS_{str(scenario)}'] == 1]\n","  biogas_tts.reset_index(inplace = True, drop = True)\n","  for wwtp in biogas_tts['CWNS_NUM']:\n","    if biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp][['C1E','B1E','D1E','F1E','H1E','N1E','I1E','G1E','O1E']].values.sum() > 0:\n","        biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp, 'Assigned an E train?'] = 'Yes'\n","    else:\n","        biogas_tts.loc[biogas_tts['CWNS_NUM'] == wwtp, 'Assigned an E train?'] = 'No'\n","\n","  #create a column that contains which treatment train(s) a facility was assigned\n","  tts = ['LAGOON', 'LAGOON_AER','LAGOON_ANAER', 'LAGOON_FAC', 'STBL_POND', 'C1', 'C1E','C2', 'C3', 'C5', 'C6','B1', 'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E','D2', 'D3', 'D5', 'D6','E2', 'E2P', 'F1', 'F1E','I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E','G2', 'G3', 'G5', 'G6', 'H1', 'H1E','N1', 'N1E','N2', 'O1', 'O1E', 'O2', 'O3', 'O5','O6']\n","  biogas_tts['TT_ASSIGNED'] = np.nan\n","  biogas_tts['TT_ASSIGNED'] = biogas_tts['TT_ASSIGNED'].astype('object')\n","  for row in range(0,biogas_tts.shape[0]):\n","    tt_curr = []\n","    for tt in tts:\n","      if biogas_tts.iloc[row][tt] == 1:\n","        tt_curr = tt_curr + [tt]\n","    biogas_tts.at[row,'TT_ASSIGNED'] = tt_curr\n","\n","  #for facilities that reported electricity generation but were not assigned an 'E' train, override to the electricity-producing version of the treatment train\n","  override = biogas_tts.loc[((biogas_tts['TT_ASSIGN_NOTE'] == 'Assigned based on partial unit process information based on common treatment trains of similar size in EPA region') | (biogas_tts['TT_ASSIGN_NOTE'] == 'Assigned based on common treatment trains of similar size in EPA region')) & (biogas_tts['Assigned an E train?'] == 'No')].reset_index(drop = True)\n","  for index, row in override.iterrows():\n","    tts = row['TT_ASSIGNED']\n","    #if just one treatment train identified, switch to electricity-producing version of that train\n","    if len(tts) == 1:\n","      if tts[0] != 'E2P':\n","        override.at[index, tts[0]] = 0\n","        override.at[index, tts[0] + 'E'] = 1\n","    #if multiple treatment trains were identified, switch to electricity-producing version of those trains\n","    else:\n","      for tt in tts:\n","        if tts[0] != 'E2P':\n","          override.at[index, tt] = 0\n","          override.at[index, tt + 'E'] = 1\n","\n","  #add new electricity-producing trains into main dataframe\n","  override.drop(columns = ['Assigned an E train?','TT_ASSIGNED'], inplace = True)\n","  tt_werf_scenario_final = tt_werf_scenario_final[~tt_werf_scenario_final['CWNS_NUM'].isin(override['CWNS_NUM'])]\n","  tt_werf_scenario_final = pd.concat([tt_werf_scenario_final, override], axis = 0)"],"metadata":{"id":"mKSRQ3aDt1GA"},"id":"mKSRQ3aDt1GA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#for facilities that reported using biogas to generate electricity, but were not assigned an electricity-producing train due to a lack of unit process information, manually correct treatment train assignment based on publicly available information\n","if (method == 'El Abbadi et al., 2025') & (scenario != 2012):\n","  #treatment train dataframe is corrected rather than the cumulative unit process list because it is simpler to identify facilities that need biogas corrections after treatment train assignment rather than before\n","  #Kitsap Co SD #7 WWTP; online checks show that wwtp has primary, activated sludge, anaerobic digestion, and nitrification\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '53002625501', 'STBL_POND'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '53002625501', 'F1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '53002625501', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #NEW HAVEN EAST SHORE WPCF; online checks show that wwtp generates energy using incinerator\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '09000930003', 'B1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '09000930003', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #STEPHENSON WTP; online checks show that wwtp uses a trickling filter\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '26002047001', 'STBL_POND'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '26002047001', 'D1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '26002047001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #BUCKLIN PT STP; online checks show that wwtp has nitrogen removal and activated sludge\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '44000031001', 'LAGOON'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '44000031001', 'I1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '44000031001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #POCATELLO STP; online checks show that wwtp has ammonia and phosphorous removal\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '16000001001', 'LAGOON_AER'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '16000001001', 'G1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '16000001001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Riverside WPCF; online checks show that wwtp uses membrane bioreactors\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06008001001', 'STBL_POND'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06008001001', 'N1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06008001001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Springfield SW WWTP; online checks show that wwtp uses chemical and biological phosphorus removal\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001026001', 'E2P'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001026001', 'H1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001026001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024))'\n","\n","  #RM Clayton WRP; online checks show that  wwtp uses membrane bioreactors\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '13000012004', 'LAGOON_ANAER'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '13000012004', 'N1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '13000012004', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Landis Sewerage Authority - CS/STP; online checks show that wwtp has nitrification and anaerobic digestion\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '34005051001', 'STBL_POND'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '34005051001', 'F1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '34005051001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #METROPOLITAN WWTP; online checks show that wwtp generates energy using incinerator\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '27000001001', 'G1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '27000001001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Davis, City of WWTP; online checks show that wwtp replaced oxidation pond with activated sludge and digestion\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06005205001', 'LAGOON_AER'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06005205001', 'B1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06005205001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #DELHI TWP WWTP; online checks show that wwtp uses primary treatment, anaerobic digestion, and nitrification\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '26000054001', 'STBL_POND'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '26000054001', 'F1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '26000054001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #South Columbus WRP; online checks show that wwtp uses primary treatment and anaerobic digestion\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '13000051001', 'LAGOON_AER'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '13000051001', 'B1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '13000051001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Sunnyvale, City of (WPCP); online checks show that wwtp uses ponding process and generates electricity\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06002008001', 'B1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06002008001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Bakersfield WWTP #2; online checks show that wwtp uses trickling filter\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06005010001', 'D1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06005010001', 'LAGOON_AER'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '06005010001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #MILWAUKEE MSD COMBINED - South Shore; online checks show that wwtp uses nitrification\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '55000000052', 'F1'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '55000000052', 'F1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '55000000052', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Lemay WWTP; online checks show that wwtp uses incinerator and anaerobic digestion\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023002', 'B6'] = 0\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023002', 'B1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023002', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'\n","\n","  #Bissell Point WWTP; online checks show that wwtp uses incinerator, trickling filter, and digestion\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023001', 'B6'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023001', 'D6'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023001', 'B1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023001', 'D1E'] = 1\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['CWNS_NUM'] == '29001023001', 'UP_ID_NOTE'] = 'Corrected based on manual check of facilities that utilize biogas to produce electricity (2024)'"],"metadata":{"id":"1t5lwYxTnfL2"},"id":"1t5lwYxTnfL2","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Reformat and export dataframe"],"metadata":{"id":"3w6i686kwumv"},"id":"3w6i686kwumv"},{"cell_type":"code","execution_count":null,"id":"Dz80Q3AsknY0","metadata":{"id":"Dz80Q3AsknY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767636937520,"user_tz":480,"elapsed":79,"user":{"displayName":"Abigayle Hodson","userId":"02880304820331263887"}},"outputId":"7fe36273-9d0d-4807-aebc-86c12369b1d9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3507813357.py:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  tt_werf_scenario_final.rename(columns = {'LAGOON':'LAGOON_OTHER'}, inplace = True)\n"]}],"source":["#rename LAGOON column to indicate that type of lagoon was not specified\n","tt_werf_scenario_final.rename(columns = {'LAGOON':'LAGOON_OTHER'}, inplace = True)\n","tt_werf_scenario_final['LAGOON_UNCATEGORIZED'] = tt_werf_scenario_final[['LAGOON_OTHER','STBL_POND']].max(axis=1)\n","tt_werf_scenario_final.drop(columns = ['LAGOON_OTHER','STBL_POND'], inplace = True)\n","\n","#reset the 'TT_IDENTIFIED' column to account for manual corrections\n","if (method == 'El Abbadi et al., 2025'):\n","  tt_werf_scenario_final['TT_IDENTIFIED'] = tt_werf_scenario_final[['LAGOON_UNCATEGORIZED', 'LAGOON_AER', 'LAGOON_ANAER','LAGOON_FAC', 'C1', 'C1E', 'C2', 'C3', 'C5', 'C6', 'B1','B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E', 'D2', 'D3', 'D5', 'D6', 'E2','E2P', 'F1', 'F1E', 'I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E', 'G2','G3', 'G5', 'G6', 'H1', 'H1E', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6']].sum(axis = 1)\n","\n","  if scenario != 2012:\n","    #for facilities where the unit process nitrification was added via the 'PRES_AMMONIA_REMOVAL' column, add a note to the UP_ID_NOTE column\n","    tt_werf_scenario_final.loc[tt_werf_scenario_final['NIT_FLAG'] == 1, 'UP_ID_NOTE_2'] = 'Nitrification unit process added via \"PRES_AMMONIA_REMOVAL\" column (2024)'\n","    tt_werf_scenario_final.loc[tt_werf_scenario_final['UP_ID_NOTE'] == 'nan', 'UP_ID_NOTE'] = np.nan\n","    tt_werf_scenario_final.loc[tt_werf_scenario_final['UP_ID_NOTE_2'] == 'nan', 'UP_ID_NOTE_2'] = np.nan\n","\n","    for index, row in tt_werf_scenario_final.iterrows():\n","      if pd.isna(row['UP_ID_NOTE_2']) == False:\n","        if pd.isna(row['UP_ID_NOTE']) == True:\n","          tt_werf_scenario_final.at[index, 'UP_ID_NOTE'] = row['UP_ID_NOTE_2']\n","        else:\n","          tt_werf_scenario_final.at[index, 'UP_ID_NOTE'] = row['UP_ID_NOTE'] + '; ' + row['UP_ID_NOTE_2']\n","\n","    #reoder columns\n","    tt_werf_scenario_final = tt_werf_scenario_final[['CWNS_NUM', 'AED', 'AND', 'AS', 'AS-A2O', 'AS-BDENIT',\n","        'AS-EA', 'AS-OD', 'AS-P', 'AS-PUREO', 'AS-SA', 'AS-SBR', 'BDENIT',\n","        'BIO-P', 'BIODRY', 'BNIT', 'BNR', 'BS_LAGOON', 'CHEM-P',\n","        'DISINF-O3', 'FBI', 'LAND_TRT', 'LIME', 'MBR-BNR', 'MHI', 'NIT','PRIMARY',\n","          'TF', 'TF-BF', 'TF-RBC', 'SUM_AS', 'TF_ALL', 'BASIC_AS',\n","        'AS_BNR_N', 'AS_BNR_P', 'COUNT_UP', f'BIOGAS_{str(scenario)}', f'{str(scenario)}_FLOW_MGD',\n","          f'{str(scenario)}_FLOW_CAT_MGD', 'EPA_REGION','LAGOON_UNCATEGORIZED', 'LAGOON_AER', 'LAGOON_ANAER',\n","        'LAGOON_FAC', 'C1', 'C1E', 'C2', 'C3', 'C5', 'C6', 'B1',\n","        'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E', 'D2', 'D3', 'D5', 'D6', 'E2',\n","        'E2P', 'F1', 'F1E', 'I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E', 'G2',\n","        'G3', 'G5', 'G6', 'H1', 'H1E', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6',\n","        'TT_IDENTIFIED', 'TT_ASSIGN_NOTE', 'UP_ID_NOTE']]\n","  else:\n","    #reoder columns\n","    tt_werf_scenario_final = tt_werf_scenario_final[['CWNS_NUM', 'AED', 'AND', 'AS', 'AS-A2O', 'AS-BDENIT',\n","    'AS-EA', 'AS-OD', 'AS-P', 'AS-PUREO', 'AS-SA', 'AS-SBR', 'BDENIT',\n","    'BIO-P', 'BIODRY', 'BNIT', 'BNR', 'BS_LAGOON', 'CHEM-P',\n","    'DISINF-O3', 'FBI', 'LAND_TRT', 'LIME', 'MBR-BNR', 'MHI', 'NIT','PRIMARY',\n","      'TF', 'TF-BF', 'TF-RBC', 'SUM_AS', 'TF_ALL', 'BASIC_AS',\n","    'AS_BNR_N', 'AS_BNR_P', 'COUNT_UP', f'BIOGAS_{str(scenario)}', f'{str(scenario)}_FLOW_MGD',\n","      f'{str(scenario)}_FLOW_CAT_MGD', 'EPA_REGION','LAGOON_UNCATEGORIZED', 'LAGOON_AER', 'LAGOON_ANAER',\n","    'LAGOON_FAC', 'C1', 'C1E', 'C2', 'C3', 'C5', 'C6', 'B1',\n","    'B1E', 'B2', 'B3', 'B4', 'B5', 'B6', 'D1', 'D1E', 'D2', 'D3', 'D5', 'D6', 'E2',\n","    'E2P', 'F1', 'F1E', 'I1', 'I1E', 'I2', 'I3', 'I5', 'I6', 'G1', 'G1E', 'G2',\n","    'G3', 'G5', 'G6', 'H1', 'H1E', 'N1', 'N1E', 'N2', 'O1', 'O1E', 'O2', 'O3', 'O5', 'O6',\n","    'TT_IDENTIFIED', 'TT_ASSIGN_NOTE']]\n","\n","  #convert from Tarallo et al. naming convention to El Abbadi et el. naming convention\n","  crosswalk = {'B1':'*A1',\n","             'B1E':'*A1e',\n","             'B2':'*A3',\n","             'B3':'*A4',\n","             'B4':'*A2',\n","             'B5':'*A5',\n","             'B6':'*A6',\n","             'C1':'A1',\n","             'C1E':'A1e',\n","             'C2':'A3',\n","             'C3':'A4',\n","             'C5':'A5',\n","             'C6':'A6',\n","             'D1':'*C1',\n","             'D1E':'*C1e',\n","             'D2':'*C3',\n","             'D3':'*C4',\n","             'D5':'*C5',\n","             'D6':'*C6',\n","             'E2':'E3',\n","             'E2P':'*E3',\n","             'F1':'*E1',\n","             'F1E':'*E1e',\n","             'G1':'*G1',\n","             'G1E':'*G1e',\n","             'G2':'*G3',\n","             'G3':'*G4',\n","             'G5':'*G5',\n","             'G6':'*G6',\n","             'H1':'*G1-p',\n","             'H1E':'*G1e-p',\n","             'I1':'F1',\n","             'I1E':'F1e',\n","             'I2':'F3',\n","             'I3':'F4',\n","             'I5':'F5',\n","             'I6':'F6',\n","             'LAGOON_AER':'L-a',\n","             'LAGOON_ANAER':'L-n',\n","             'LAGOON_FAC':'L-f',\n","             'LAGOON_UNCATEGORIZED':'L-u',\n","             'N1':'*D1',\n","             'N1E':'*D1e',\n","             'N2':'*D3',\n","             'O1':'*B1',\n","             'O1E':'*B1e',\n","             'O2':'*B3',\n","             'O3':'*B4',\n","             'O5':'*B5',\n","             'O6':'*B6'}\n","\n","  tt_werf_scenario_final.rename(columns = crosswalk, inplace = True)\n","\n","else:\n","  #reset the 'TT_IDENTIFIED' column to account for manual corrections\n","  tt_werf_scenario_final['TT_IDENTIFIED'] = tt_werf_scenario_final[['LAGOON_UNCATEGORIZED', 'LAGOON_AER', 'LAGOON_ANAER', 'LAGOON_FAC', 'C3', 'B1', 'B1E', 'B4', 'B5', 'B6', 'D1', 'E2', 'E2P', 'F1', 'I2', 'I3', 'G1', 'G1E', 'H1', 'N1', 'N2', 'O1']].sum(axis = 1)\n","\n","  #for facilities where the unit process nitrification was added via the 'PRES_AMMONIA_REMOVAL' column, add a note to the UP_ID_NOTE column\n","  tt_werf_scenario_final.loc[tt_werf_scenario_final['NIT_FLAG'] == 1, 'UP_ID_NOTE'] = 'Nitrification unit process added via \"PRES_AMMONIA_REMOVAL\" column (2024)'\n","\n","  #reoder columns\n","  tt_werf_scenario_final = tt_werf_scenario_final[['CWNS_NUM', 'AED', 'AND', 'AS', 'AS-A2O', 'AS-BDENIT',\n","       'AS-EA', 'AS-OD', 'AS-P', 'AS-PUREO', 'AS-SA', 'AS-SBR', 'BDENIT',\n","       'BIO-P', 'BIODRY', 'BNIT', 'BNR', 'BS_LAGOON', 'CHEM-P',\n","       'DISINF-O3', 'FBI', 'LAND_TRT', 'LIME', 'MBR-BNR', 'MHI', 'NIT','PRIMARY',\n","        'TF', 'TF-BF', 'TF-RBC', 'SUM_AS', 'TF_ALL', 'BASIC_AS',\n","       'AS_BNR_N', 'AS_BNR_P', 'COUNT_UP', f'BIOGAS_{str(scenario)}', f'{str(scenario)}_FLOW_MGD',\n","       f'{str(scenario)}_FLOW_CAT_MGD', 'EPA_REGION','LAGOON_UNCATEGORIZED', 'LAGOON_AER', 'LAGOON_ANAER',\n","       'LAGOON_FAC', 'C3', 'B1','B1E', 'B4', 'B5', 'B6', 'D1', 'E2',\n","       'E2P', 'F1', 'I2', 'I3', 'G1', 'G1E', 'H1', 'N1', 'N2', 'O1',\n","       'TT_IDENTIFIED', 'TT_ASSIGN_NOTE', 'UP_ID_NOTE']]"]},{"cell_type":"code","execution_count":null,"id":"0Ktam0VCK6Gx","metadata":{"id":"0Ktam0VCK6Gx"},"outputs":[],"source":["#manual corrections to flow rates of large wwtps\n","if (method == 'El Abbadi et al., 2025') & scenario == 2022:\n","  #read in spreadsheet that contains manually corrected flow rates for top 50 wwtps by flow rate (checks done by Heroda Abera, 2024)\n","  flow_checks = pd.read_excel(path + 'input_data/facility_information/manual_corrections/2022_flow_checks.xlsx')\n","\n","  #add leading zero to CWNS ids with less than 11 digits to ensure correct merge with final dataframe\n","  flow_checks['CWNS_NUM'] = ['0' + str(cwns) if len(str(cwns)) < 11 else str(cwns) for cwns in flow_checks['CWNS_NUM']]\n","\n","  #merge flow checks with final dataframe\n","  tt_werf_scenario_final = tt_werf_scenario_final.merge(flow_checks, how = 'left', on = 'CWNS_NUM')\n","\n","  #for wwtps that were not checked for flow rate, assume the flow reported in 2022 is correct\n","  tt_werf_scenario_final.loc[pd.isna(tt_werf_scenario_final['FLOW_2022_MGD (CHECKED)']),'FLOW_2022_MGD (CHECKED)'] = tt_werf_scenario_final.loc[pd.isna(tt_werf_scenario_final['FLOW_2022_MGD (CHECKED)']),'FLOW_2022_MGD']\n","  tt_werf_scenario_final.rename(columns = {'FLOW_2022_MGD (CHECKED)':'FLOW_2022_MGD_FINAL'}, inplace = True)\n","\n","  #drop duplicates\n","  tt_werf_scenario_final = tt_werf_scenario_final.drop_duplicates()"]},{"cell_type":"code","execution_count":null,"id":"S8mJQAF4kg9D","metadata":{"id":"S8mJQAF4kg9D"},"outputs":[],"source":["#check for duplicates\n","assert tt_werf_scenario_final['CWNS_NUM'].value_counts().max() == 1, 'Duplicate CWNS numbers found'\n","\n","#export to csv to be used for energy and greenhouse gas emissions calculations\n","tt_werf_scenario_final.to_csv(path + f'input_data/configuration_methods/{method}/tt_assignments_{str(scenario)}.csv', index = False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}